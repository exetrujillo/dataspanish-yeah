{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "745783461938421bb2382af71b58080d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DropdownModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DropdownModel",
            "_options_labels": [
              "Abrazar mi inmensa soledad en el destello púrpura del blur nocturno",
              "Agarré el colectivo para ir al centro.",
              "Andé por todo el centro buscando una tienda abierta.",
              "Aunque llovía torrencialmente y la carretera estaba resbaladiza, decidimos seguir nuestro camino, convencidos de que llegaríamos a tiempo para la reunión, aunque, en el fondo, sabíamos que era poco probable.",
              "Aunque me encantaría acompañarte al concierto, cuyo cartel anuncia a varias bandas que admiro desde la adolescencia, debo priorizar la entrega del informe que mi jefe, bastante exigente por cierto, me ha pedido para mañana a primera hora.",
              "Aunque tenía sueño, decidió seguir estudiando porque el examen era al día siguiente.",
              "Ayer habían muchas personas en el parque.",
              "Ayer se descompuso mi carro.",
              "Correr rápido él parque ayer.",
              "Cuántas copas tenés!?",
              "Dijistes que ibas a venir temprano.",
              "Echar agua al mar.",
              "El ADN mitocondrial solo se hereda por vía materna.",
              "El CEO anunció que van a pivotar el negocio hacia el e-commerce.",
              "El CEO, tipo super ocupado con su jet privado y sus reuniones en la nube, me soltó un 'feedback' diciendo que hay que 'pivotear la estrategia para optimizar el customer journey', pero yo flipé porque ni él mismo se cree esa retórica corporativa.",
              "El algoritmo de backpropagation ajusta los pesos de la red neuronal mediante la minimización del error.",
              "El autobús se llenó de pibes ruidosos.",
              "El chef, tras haber trabajado en los mejores restaurantes de París y Tokio, donde perfeccionó técnicas que luego fusionaría con ingredientes autóctonos, decidió abrir un pequeño local en su ciudad natal, la cual nunca dejó de amar a pesar de sus constantes viajes.",
              "El científico, quien había dedicado décadas a estudiar los efectos del cambio climático en los ecosistemas marinos, publicó un informe alarmante que, sin embargo, fue ignorado por las autoridades, a pesar de las advertencias de la comunidad internacional.",
              "El colapso de la función de onda ocurre al realizar una medición en un sistema cuántico.",
              "El concierto estuvo brutal, hermano.",
              "El correr rápido los árboles mientras el sol brillaba noche las estrellas cantaban canciones de verde melancolía bajo un mar de nubes rugientes",
              "El cura la cura con fe.",
              "El código tiene una fuga de memoria en la función recursiva.",
              "El elefante volador dibujó un círculo en el cielo con su trompa.",
              "El equipo de desarrollo debugueó el código.",
              "El frío gris de la sangre que llevo dentro",
              "El influencer subió un unboxing del último iPhone.",
              "El informe que enviaste ayer, el cual revisé esta mañana, tiene algunos errores de formato.",
              "El juez dictó la sentencia con dureza.",
              "El libro que compré ayer, el cual fue recomendado por mi profesor de literatura, trata sobre la influencia del realismo mágico en la narrativa latinoamericana contemporánea.",
              "El libro que me recomendaste ayer tiene una trama muy compleja.",
              "El mar susurraba historias antiguas al oído del viento.",
              "El metaverso promete cambiar la forma en que interactuamos digitalmente.Vi a mi amigo con los prismáticos.",
              "El ministro dio un discurso en la banca.",
              "El modelo de machine learning sobreajustó los datos de entrenamiento.",
              "El niño come caramelos y su hermano también.",
              "El organismo acogió los requerimientos de la oposición que señalaban que la socióloga de 80 años infringió la Carta Fundamental al participar de la fallida compraventa al Estado de la propiedad de su familia en calle Guardia Vieja.",
              "El paciente tiene un caso grave de caso.",
              "El principio de incertidumbre impide conocer con precisión la posición y velocidad de una partícula.",
              "El profesor, quien había ganado varios premios, presentó su nuevo libro en la universidad.",
              "El protocolo HTTPS cifra la comunicación entre el cliente y el servidor.",
              "El servidor se cayó justo cuando iba a hacer la compra online.",
              "El seseo es una característica fonético-fonológica de muchas variedades de las lenguas española y gallega consistente en la existencia de un único fonema fricativo coronal que es pronunciado como una fricativa alveolar sorda [s]",
              "El silencio gritaba más que las palabras.",
              "El test dio un falso positivo.",
              "El tiempo vuela sin mirar atrás.",
              "El tweet se hizo viral en cuestión de minutos.",
              "El video se hizo viral en TikTok.",
              "El viento susurraba secretos entre las hojas de los árboles.",
              "Entre 1790 y 1800 en Francia, los districts fueron el primer nivel de subdivisión de los départements, y fueron posteriormente reemplazados por los arrondissements",
              "Entre las grietas del tiempo, donde habitan los recuerdos olvidados y las promesas rotas, encontré las palabras que jamás te dije, aquellas que se quedaron suspendidas como hojas secas en el aire estático de un otoño perpetuo.",
              "Ese examen estuvo facilito",
              "Ese reloj vale un ojo de la cara.",
              "Estar en las nubes.",
              "Este finde vamos a pegar alto carrete.",
              "Estoy hasta la coronilla con este taco",
              "Habían muchas personas en la sala.",
              "Hazme un like en el post.",
              "Juan vio a Pedro cansado.",
              "La app crasheó al subir el archivo pesado.",
              "La batería está baja.",
              "La data está corrupta en el sistema.",
              "La democracia, ese frágil entramado de consensos y disensos que se teje entre el clamor de las calles y el silencio de los despachos, requiere de ciudadanos no sólo informados sino profundamente comprometidos con la defensa de valores que trascienden intereses particulares.",
              "La fotosíntesis convierte la energía solar en energía química en forma de glucosa",
              "La inteligencia artificial generativa está revolucionando la industria.",
              "La jirafa alta del zoológico duerme de pie.",
              "La llave de la caja está rota.",
              "La luz verde indica que puedes avanzar.",
              "La noche, con su manto de estrellas temblorosas que parecen susurrar secretos ancestrales, envolvía la ciudad dormida donde los sueños y las pesadillas se fundían en un baile eterno bajo la mirada indiferente de la luna.",
              "La nostalgia es un río que arrastra los recuerdos.",
              "La novela, escrita en un estilo que mezcla el realismo mágico con la crítica social, y ambientada en un pueblo donde el tiempo parece haberse detenido, narra la historia de tres generaciones de mujeres que luchan contra las convenciones de una sociedad profundamente machista.",
              "La sombra del pez nadaba sobre la luna reflejada en el agua.",
              "Las estrellas titilaban como ojos curiosos en la noche infinita.",
              "Las montañas suspiraban de alivio cuando cayó la primera nieve.",
              "Las sombras bailaban al compás de la luna.",
              "Le dieron gato por liebre.",
              "Los clientes que se registraron en la preventa recibirán un descuento especial.",
              "Los colores de la música pintaban el aire de azul y rojo.",
              "Los corazones palpitan y palpitan",
              "Los estudiantes, algunos de los cuales habían viajado desde provincias lejanas para asistir al seminario, expresaron su frustración cuando, tras horas de espera en un auditorio mal ventilado, se anunció que el ponente principal había cancelado su participación por motivos de salud.",
              "Los recuerdos se desvanecen como huellas en la arena.",
              "Me cancelaron en Twitter por mi último comentario.",
              "Me ghosteó después de tres días de hablar sin parar.",
              "Me pilló el atasco y llegué tarde.",
              "Me se olvidó tu nombre.",
              "Messi es lo más grande del mundo",
              "Más vale tarde que nunca.",
              "Necesito actualizar el software del router para mejorar el performance de la red.",
              "Necesito ir al banco.",
              "Oye, bro, ¿qué onda con el vacile de esta noche?",
              "Para realizar la configuración óptima del dispositivo, asegúrese de verificar que los puertos de entrada, los cuales suelen ubicarse en la parte posterior según el modelo adquirido, estén correctamente alineados con los conectores del cable HDMI, evitando así posibles fallos de transmisión de datos durante el proceso de sincronización.",
              "Poner manos a la obra.",
              "Pásame la lima del escritorio.",
              "Qué facha tenés hoy, amigo!",
              "Se armó el desmadre en la fiesta anoche.",
              "Se informa a los pasajeros que el vuelo ha sido cancelado debido a condiciones meteorológicas adversas.",
              "Se me antojó una sopaipilla",
              "Se me ha muerto el móvil otra vez.",
              "Se me rompió el móvil otra vez.",
              "Si hubieras llegado a tiempo, como te pedí repetidamente por mensaje, y no te hubieras quedado atrapado en el tráfico, que según dijiste fue causado por un accidente, habríamos podido evitar esta situación incómoda que ahora nos obliga a replantear todo el proyecto.",
              "Si hubieras llegado más temprano, habríamos alcanzado el último tren.",
              "Si hubieras venido, lo habrías visto.",
              "Si yo sabría que iba a llover, habría traído paraguas.",
              "Sus palabras eran dagas afiladas.",
              "Sus palabras eran puñales que se clavaban en el alma.",
              "Tiré de la cadena y se rompió.",
              "Tuvo que de volver el libro.",
              "Un reloj sin tiempo marca la eternidad.",
              "Vi a la mujer con el sombrero rojo.",
              "Vi al hombre con el telescopio.",
              "Voy a hacer un streaming en Twitch esta noche.",
              "Voy a la guagua, ya es tarde.",
              "Voy a la tienda a comprar un refresco.",
              "pucha vecino, no me quedan más bolsitas",
              "¡Ché, qué quilombo este trámite!",
              "¿Acaso crees que esto es un juego?",
              "¿Cuántas veces tengo que decirlo?",
              "¿Cómo puede algo tan simple ser tan complicado?",
              "¿Cómo que no sabías eso?",
              "¿Me pasás la birra?",
              "¿Vos tenés frío o calor?"
            ],
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "DropdownView",
            "description": "Elige una frase:",
            "description_tooltip": null,
            "disabled": false,
            "index": 91,
            "layout": "IPY_MODEL_45420b3659c14f889d3e29bda42427a0",
            "style": "IPY_MODEL_c0104f5e59b249b59ebac045e2559100"
          }
        },
        "45420b3659c14f889d3e29bda42427a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "95%"
          }
        },
        "c0104f5e59b249b59ebac045e2559100": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": "initial"
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "cellView": "form",
        "id": "56snR3szVSYC"
      },
      "outputs": [],
      "source": [
        "# @title 0. Configuración Inicial y Librerías\n",
        "\n",
        "# --- 0.1 Instalar Librerías ---\n",
        "# Instalamos/actualizamos las librerías necesarias.\n",
        "# - google-generativeai: Para interactuar con la API de Gemini.\n",
        "# - pandas: Para manejar el archivo CSV.\n",
        "# - numpy: Para operaciones numéricas (arrays de embeddings).\n",
        "# - scikit-learn: Incluye PCA y otras utilidades (aunque usaremos umap por separado).\n",
        "# - plotly: Para gráficos interactivos.\n",
        "# - umap-learn: Para la reducción de dimensionalidad UMAP (buena para visualización).\n",
        "# - nltk: Para dividir frases en sentencias (tokenización).\n",
        "print(\"--- 0.1 Instalando librerías necesarias ---\")\n",
        "!pip install -q -U google-generativeai pandas numpy scikit-learn plotly umap-learn nltk\n",
        "print(\"Librerías base instaladas/actualizadas.\\n\")\n",
        "\n",
        "# --- 0.2 Importar Librerías ---\n",
        "print(\"--- 0.2 Importando librerías ---\")\n",
        "try:\n",
        "    import google.generativeai as genai\n",
        "    import pandas as pd\n",
        "    import numpy as np\n",
        "    import os # Para manejo de rutas de archivo\n",
        "    import json # Para trabajar con la columna JSON del CSV\n",
        "    import random # Para seleccionar una fila de muestra\n",
        "    import plotly.express as px # Para gráficos fáciles e interactivos\n",
        "    from sklearn.decomposition import PCA # Como opción de reducción de dimensionalidad\n",
        "    import umap # Para reducción de dimensionalidad UMAP\n",
        "    import nltk # Para procesamiento de lenguaje natural (tokenización de frases)\n",
        "    from google.colab import widgets # Para el dropdown de selección de frases\n",
        "    import textwrap # Para acortar texto largo en las impresiones\n",
        "    from google.colab import userdata # Para gestionar la API Key de forma segura\n",
        "\n",
        "    print(\"Librerías principales importadas correctamente.\\n\")\n",
        "except ImportError as e:\n",
        "    print(f\"(!) Error importando una librería esencial: {e}\")\n",
        "    print(\"Por favor, verifica la instalación en el paso 0.1.\")\n",
        "    # Podrías detener la ejecución aquí si una librería crítica falla\n",
        "    raise # Detiene la ejecución de la celda si falla una importación crítica\n",
        "\n",
        "# --- 0.3 Configurar API Key de Gemini ---\n",
        "print(\"--- 0.3 Configurando API Key de Gemini ---\")\n",
        "api_key_configured = False # Bandera para saber si se configuró\n",
        "try:\n",
        "    # Intenta obtener la API Key desde los Secrets de Colab (método recomendado)\n",
        "    # Debes haberla guardado con el nombre 'GOOGLE_API_KEY'\n",
        "    GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')\n",
        "    genai.configure(api_key=GOOGLE_API_KEY)\n",
        "    print(\"API Key de Gemini configurada correctamente desde Secrets.\")\n",
        "    api_key_configured = True\n",
        "except userdata.SecretNotFoundError:\n",
        "    print(\"(!) Advertencia: Secret 'GOOGLE_API_KEY' no encontrado.\")\n",
        "    print(\"Por favor, ve a los 'Secrets' de Colab (Panel izquierdo -> Icono de llave) y añade tu API key.\")\n",
        "    print(\"Las llamadas a la API fallarán sin una clave válida.\")\n",
        "except Exception as e:\n",
        "    print(f\"(!) Ocurrió un error inesperado al configurar la API Key: {e}\")\n",
        "    print(\"Las llamadas a la API podrían fallar.\")\n",
        "\n",
        "# --- 0.4 Descargar Recursos NLTK ---\n",
        "# Necesitamos el tokenizador 'punkt' para dividir texto en frases/sentencias.\n",
        "print(\"\\n--- 0.4 Descargando recursos de NLTK (punkt) ---\")\n",
        "try:\n",
        "    nltk.download('punkt', quiet=True) # quiet=True evita mucho texto en la salida\n",
        "    # Verificar que se pueda usar (opcional pero bueno)\n",
        "    nltk.sent_tokenize(\"Esto es una prueba. Funciona.\")\n",
        "    print(\"Recursos NLTK 'punkt' descargados y verificados.\")\n",
        "except Exception as e:\n",
        "    print(f\"(!) Error al descargar/verificar recursos de NLTK 'punkt': {e}\")\n",
        "    print(\"La funcionalidad para dividir frases en sentencias podría fallar más adelante.\")\n",
        "\n",
        "# --- 0.5 Definir Constantes de Modelos (Ajusta si prefieres otros) ---\n",
        "# Usamos nombres de modelos recomendados y generalmente disponibles.\n",
        "# Puedes cambiarlos si tienes acceso a versiones específicas o experimentales.\n",
        "EMBEDDING_MODEL_NAME = 'embedding-001' # O el modelo experimental cuando deja hacerlo.\n",
        "LLM_MODEL_NAME = 'gemini-1.5-flash'   # Modelo rápido y capaz para generar el Meta-CoT.\n",
        "                                      # Alternativa: 'gemini-1.5-pro-latest' (más potente, potencialmente más lento/costoso)\n",
        "print(f\"\\n--- 0.5 Constantes Definidas ---\")\n",
        "print(f\"Modelo de Embedding a usar: '{EMBEDDING_MODEL_NAME}'\")\n",
        "print(f\"Modelo LLM para Meta-CoT: '{LLM_MODEL_NAME}'\")\n",
        "\n",
        "# --- 0.6 Verificación Final ---\n",
        "print(\"\\n--- 0.6 Verificación Final ---\")\n",
        "if not api_key_configured:\n",
        "    print(\"(!) ATENCIÓN: La API Key no está configurada. Debes añadirla a los Secrets para continuar.\")\n",
        "else:\n",
        "    print(\"Configuración inicial completada. ¡Listo para el siguiente paso!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 1. Carga, Limpieza y Exploración Inicial del CSV desde `sample_data`\n",
        "\n",
        "import pandas as pd\n",
        "import os\n",
        "import random\n",
        "import textwrap\n",
        "\n",
        "# --- Parámetros del Usuario ---\n",
        "# @markdown 1. **Verifica la subida:** Asegúrate de que tu archivo CSV (con análisis CoT/JSON) esté en la carpeta `sample_data` en el panel izquierdo.\n",
        "# @markdown 2. **Introduce el NOMBRE EXACTO** de tu archivo CSV (incluyendo `.csv`):\n",
        "nombre_archivo_csv_analisis = \"datos_filtrados.csv\" # @param {type:\"string\"}\n",
        "\n",
        "# @markdown 3. **Columnas Esperadas:** Confirma los nombres de las columnas clave (sensible a mayúsculas/minúsculas):\n",
        "columna_frase_original = \"frase\" # @param {type:\"string\"}\n",
        "columna_cot = \"Complex.CoT\" # @param {type:\"string\"}\n",
        "columna_respuesta_json = \"respuesta\" # @param {type:\"string\"}\n",
        "# --- Fin Parámetros ---\n",
        "\n",
        "# Variable global para almacenar el DataFrame cargado y limpio\n",
        "df_analisis = None\n",
        "\n",
        "# Construir la ruta completa al archivo dentro del entorno de Colab\n",
        "ruta_csv_completa = os.path.join(\"/content/sample_data\", nombre_archivo_csv_analisis)\n",
        "\n",
        "print(f\"--- 1.1 Intentando cargar datos desde: {ruta_csv_completa} ---\")\n",
        "\n",
        "# Verificar si el archivo existe\n",
        "if not nombre_archivo_csv_analisis or not nombre_archivo_csv_analisis.endswith('.csv'):\n",
        "     print(\"(!) Error: Debes proporcionar un nombre de archivo CSV válido (que termine en .csv).\")\n",
        "elif not columna_frase_original or not columna_cot or not columna_respuesta_json:\n",
        "     print(\"(!) Error: Debes especificar los nombres de las tres columnas clave (frase, CoT, respuesta JSON).\")\n",
        "elif os.path.exists(ruta_csv_completa):\n",
        "    try:\n",
        "        # Leer el CSV\n",
        "        df_cargado_temp = pd.read_csv(ruta_csv_completa)\n",
        "        print(f\"-> Archivo CSV cargado inicialmente con {df_cargado_temp.shape[0]} filas.\")\n",
        "\n",
        "        # Verificar la existencia de las columnas clave\n",
        "        columnas_necesarias = [columna_frase_original, columna_cot, columna_respuesta_json]\n",
        "        columnas_faltantes = [col for col in columnas_necesarias if col not in df_cargado_temp.columns]\n",
        "\n",
        "        if not columnas_faltantes:\n",
        "            print(f\"-> Columnas esperadas ({', '.join(columnas_necesarias)}) encontradas.\")\n",
        "\n",
        "            # --- 1.1.1 Limpieza de Duplicados Exactos ---\n",
        "            print(\"\\n--- 1.1.1 Verificando y eliminando duplicados exactos ---\")\n",
        "            filas_antes = len(df_cargado_temp)\n",
        "            # drop_duplicates sin 'subset' considera TODAS las columnas\n",
        "            df_limpio = df_cargado_temp.drop_duplicates(keep='first') # Mantener la primera ocurrencia\n",
        "            filas_despues = len(df_limpio)\n",
        "            filas_eliminadas = filas_antes - filas_despues\n",
        "\n",
        "            if filas_eliminadas > 0:\n",
        "                 print(f\"-> Se eliminaron {filas_eliminadas} fila(s) que eran duplicados exactos en todas las columnas.\")\n",
        "                 print(f\"-> El DataFrame ahora tiene {filas_despues} filas.\")\n",
        "            else:\n",
        "                 print(\"-> No se encontraron filas completamente duplicadas.\")\n",
        "\n",
        "            # Asignar el DataFrame limpio a la variable global\n",
        "            df_analisis = df_limpio\n",
        "            print(\"-> DataFrame limpio asignado a 'df_analisis'.\")\n",
        "\n",
        "        else: # Si faltaban columnas necesarias\n",
        "            print(f\"(!) Error CRÍTICO: Faltan las siguientes columnas esenciales en el CSV: {', '.join(columnas_faltantes)}\")\n",
        "            print(f\"   Columnas encontradas en el archivo: {list(df_cargado_temp.columns)}\")\n",
        "            print(\"   No se continuará con la limpieza ni asignación.\")\n",
        "\n",
        "    except pd.errors.EmptyDataError:\n",
        "        print(f\"(!) Error: El archivo CSV en '{ruta_csv_completa}' parece estar vacío.\")\n",
        "    except Exception as e:\n",
        "        print(f\"(!) Error inesperado al leer o procesar el archivo CSV: {e}\")\n",
        "\n",
        "else: # Si el archivo no existe\n",
        "    print(f\"(!) Error CRÍTICO: Archivo '{nombre_archivo_csv_analisis}' NO encontrado en '/content/sample_data/'.\")\n",
        "    # ... (mensajes de ayuda para subir archivo) ...\n",
        "\n",
        "# --- 1.2 Exploración (Si el DataFrame se limpió y asignó correctamente) ---\n",
        "if df_analisis is not None:\n",
        "    print(\"\\n--- 1.2 Información General del DataFrame Limpio ('df_analisis') ---\") # Cambiado a \"Limpio\"\n",
        "    print(f\"-> Dimensiones: {df_analisis.shape[0]} filas x {df_analisis.shape[1]} columnas\")\n",
        "\n",
        "    # Contar frases únicas (ahora debería coincidir con el número de filas si las duplicadas eran exactas)\n",
        "    if columna_frase_original in df_analisis.columns:\n",
        "        num_frases_unicas = df_analisis[columna_frase_original].nunique()\n",
        "        print(f\"-> Número de frases únicas en la columna '{columna_frase_original}': {num_frases_unicas}\")\n",
        "        if num_frases_unicas != df_analisis.shape[0]:\n",
        "             print(f\"   (!) Nota: Todavía hay {df_analisis.shape[0] - num_frases_unicas} frases que aparecen en múltiples filas, pero estas filas difieren en las columnas CoT o respuesta.\")\n",
        "    else:\n",
        "         print(f\"(!) Advertencia: La columna '{columna_frase_original}' no se encontró para contar únicos.\")\n",
        "\n",
        "    # --- 1.3 Muestra Aleatoria (del DataFrame limpio) ---\n",
        "    print(\"\\n--- 1.3 Muestra Aleatoria de una Fila del DataFrame Limpio ---\")\n",
        "    if not df_analisis.empty:\n",
        "        try:\n",
        "            random_row = df_analisis.sample(1).iloc[0]\n",
        "            print(f\"Mostrando contenido de la Fila con índice original: {random_row.name}\") # El índice puede haber cambiado\n",
        "\n",
        "            for col_name in columnas_necesarias:\n",
        "                cell_content = str(random_row[col_name])\n",
        "                shortened_content = textwrap.shorten(cell_content, width=200, placeholder=\"...\")\n",
        "                print(f\"\\n  [{col_name}]:\")\n",
        "                print(f\"    {shortened_content}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"(!) Error al generar la muestra aleatoria: {e}\")\n",
        "    else:\n",
        "        print(\"-> El DataFrame está vacío después de la limpieza, no se puede mostrar muestra.\")\n",
        "\n",
        "    print(\"\\n--- Fin Exploración Inicial ---\")\n",
        "\n",
        "else:\n",
        "    print(\"\\n(!) El DataFrame 'df_analisis' no pudo ser cargado o limpiado. Revisa los errores anteriores.\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "6lSWFJz2cC0g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 2. Selección Interactiva de la Frase\n",
        "\n",
        "# Importar ipywidgets y display\n",
        "import ipywidgets as widgets # <--- CORRECCIÓN: Usar ipywidgets\n",
        "from IPython.display import display, clear_output\n",
        "import pandas as pd # Asegurarse de que pandas esté disponible por si acaso\n",
        "\n",
        "# Variable global para almacenar el widget dropdown\n",
        "dropdown_selector_frase = None\n",
        "\n",
        "# Recuperar el nombre de la columna de la celda anterior (o definirlo si es necesario)\n",
        "# Asumiendo que 'columna_frase_original' se definió en la celda anterior (Chunk 1)\n",
        "# Si no, descomenta y ajusta la línea siguiente:\n",
        "# columna_frase_original = \"frase\"\n",
        "\n",
        "print(\"--- 2.1 Preparando Selector de Frases ---\")\n",
        "\n",
        "# Verificar que df_analisis exista y contenga la columna de frases\n",
        "if 'df_analisis' in globals() and isinstance(df_analisis, pd.DataFrame) and not df_analisis.empty:\n",
        "    if columna_frase_original in df_analisis.columns:\n",
        "\n",
        "        # Obtener la lista de frases únicas\n",
        "        # Convertir a string para evitar problemas con tipos mixtos si los hubiera\n",
        "        lista_frases_unicas = df_analisis[columna_frase_original].astype(str).unique().tolist()\n",
        "\n",
        "        # Ordenar alfabéticamente para facilitar la búsqueda\n",
        "        lista_frases_unicas.sort()\n",
        "\n",
        "        if lista_frases_unicas:\n",
        "            print(f\"-> Encontradas {len(lista_frases_unicas)} frases únicas para seleccionar.\")\n",
        "\n",
        "            # Crear el widget Dropdown usando ipywidgets\n",
        "            dropdown_selector_frase = widgets.Dropdown(\n",
        "                options=lista_frases_unicas,\n",
        "                description='Elige una frase:',\n",
        "                # Ajustar el estilo para manejar frases potencialmente largas\n",
        "                style={'description_width': 'initial'},\n",
        "                layout={'width': '95%'} # Usar un porcentaje para mejor adaptabilidad\n",
        "                # disabled=False\n",
        "            )\n",
        "\n",
        "            print(\"-> Widget Dropdown creado.\")\n",
        "\n",
        "            # --- Mostrar el Widget ---\n",
        "            print(\"\\n--- 2.2 Por favor, selecciona una frase del menú desplegable ---\")\n",
        "            display(dropdown_selector_frase)\n",
        "            print(\"--- Ejecuta la siguiente celda (Chunk 3) DESPUÉS de hacer tu selección ---\")\n",
        "\n",
        "        else:\n",
        "            print(f\"(!) Error: La columna '{columna_frase_original}' existe, pero no contiene frases únicas válidas después de la extracción.\")\n",
        "\n",
        "    else:\n",
        "        print(f\"(!) Error: La columna '{columna_frase_original}' definida en el Chunk 1 no se encuentra en 'df_analisis'.\")\n",
        "        print(\"   Asegúrate de que el nombre de la columna sea correcto y el Chunk 1 se haya ejecutado sin errores.\")\n",
        "else:\n",
        "    print(\"(!) Error: El DataFrame 'df_analisis' no existe o está vacío.\")\n",
        "    print(\"   Asegúrate de que el Chunk 1 se haya ejecutado correctamente y haya cargado los datos.\")\n",
        "\n",
        "\n",
        "# --- Nota Opcional: Cómo acceder al valor seleccionado ---\n",
        "# En la siguiente celda (Chunk 3), accederemos al valor así:\n",
        "# frase_seleccionada = dropdown_selector_frase.value\n",
        "# print(f\"Valor seleccionado actualmente: {dropdown_selector_frase.value}\") # Para probar ahora mismo si quieres"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156,
          "referenced_widgets": [
            "745783461938421bb2382af71b58080d",
            "45420b3659c14f889d3e29bda42427a0",
            "c0104f5e59b249b59ebac045e2559100"
          ]
        },
        "cellView": "form",
        "id": "_gVVWjYTctAa",
        "outputId": "49e27cde-d5eb-489b-b5c1-3bac0589c7cf"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- 2.1 Preparando Selector de Frases ---\n",
            "-> Encontradas 122 frases únicas para seleccionar.\n",
            "-> Widget Dropdown creado.\n",
            "\n",
            "--- 2.2 Por favor, selecciona una frase del menú desplegable ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Dropdown(description='Elige una frase:', layout=Layout(width='95%'), options=('Abrazar mi inmensa soledad en e…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "745783461938421bb2382af71b58080d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Ejecuta la siguiente celda (Chunk 3) DESPUÉS de hacer tu selección ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 3 (Modificado): Recuperar Datos, Segmentar Texto y Generar Meta-CoT\n",
        "\n",
        "import google.generativeai as genai\n",
        "import json\n",
        "import pandas as pd\n",
        "import textwrap # Para mostrar texto de forma más limpia\n",
        "import re # Para procesar la respuesta del LLM\n",
        "\n",
        "# --- 3.1 Recuperar Selección y Datos ---\n",
        "print(\"--- 3.1 Recuperando datos de la frase/texto seleccionado ---\") # Cambiado 'frase' a 'frase/texto'\n",
        "\n",
        "# (El código para verificar variables y obtener frase_seleccionada, cot_original, json_respuesta_str es el mismo)\n",
        "# ... (código de verificación inicial y obtención de datos de la fila) ...\n",
        "\n",
        "# Verificar si las variables necesarias existen\n",
        "if 'dropdown_selector_frase' not in globals() or dropdown_selector_frase is None:\n",
        "    print(\"(!) Error: El widget Dropdown ('dropdown_selector_frase') no existe.\")\n",
        "    # ... (resto del manejo de error) ...\n",
        "elif 'df_analisis' not in globals() or df_analisis is None or df_analisis.empty:\n",
        "    print(\"(!) Error: El DataFrame 'df_analisis' no existe o está vacío.\")\n",
        "    # ... (resto del manejo de error) ...\n",
        "else:\n",
        "    frase_seleccionada = dropdown_selector_frase.value\n",
        "    print(f\"-> Texto seleccionado: '{textwrap.shorten(frase_seleccionada, width=100)}'\")\n",
        "    try:\n",
        "        fila_datos = df_analisis.loc[df_analisis[columna_frase_original].astype(str) == frase_seleccionada].iloc[0]\n",
        "        print(\"-> Fila de datos encontrada.\")\n",
        "        cot_original = fila_datos[columna_cot]\n",
        "        json_respuesta_str = fila_datos[columna_respuesta_json]\n",
        "\n",
        "        # --- 3.2 Parsear la Respuesta JSON Original ---\n",
        "        print(\"\\n--- 3.2 Intentando parsear la respuesta JSON original ---\")\n",
        "        # (El código para parsear parsed_json y manejar json_parse_error es el mismo)\n",
        "        # ... (código de parseo JSON) ...\n",
        "        parsed_json = None # Inicializar\n",
        "        json_parse_error = None\n",
        "        if pd.isna(json_respuesta_str):\n",
        "             print(\"-> La columna 'respuesta' contiene NaN (Nulo).\")\n",
        "        elif isinstance(json_respuesta_str, str):\n",
        "            try:\n",
        "                parsed_json = json.loads(json_respuesta_str)\n",
        "                if isinstance(parsed_json, (dict, list)):\n",
        "                     print(\"-> JSON parseado correctamente.\")\n",
        "                else:\n",
        "                    print(f\"(!) Advertencia: JSON parseado no es dict/list (Tipo: {type(parsed_json)}).\")\n",
        "                    parsed_json = None\n",
        "            except json.JSONDecodeError as e:\n",
        "                json_parse_error = str(e)\n",
        "                print(f\"(!) Advertencia: La columna '{columna_respuesta_json}' no contiene JSON válido: {json_parse_error}\")\n",
        "            except Exception as e:\n",
        "                 json_parse_error = f\"Error inesperado al parsear JSON: {e}\"\n",
        "                 print(f\"(!) Error inesperado al parsear '{columna_respuesta_json}': {e}\")\n",
        "                 parsed_json = None\n",
        "        else:\n",
        "            print(f\"(!) Advertencia: Contenido de '{columna_respuesta_json}' no es string ni NaN.\")\n",
        "\n",
        "\n",
        "        # --- 3.3 Generar Segmentación y Meta-CoT ---\n",
        "        print(\"\\n--- 3.3 Preparando y generando Segmentación y Meta-Análisis CoT ---\")\n",
        "\n",
        "        # Variables para almacenar los resultados procesados\n",
        "        lista_unidades_detectadas = []\n",
        "        meta_cot_resumen = \"(No generado)\" # Default\n",
        "\n",
        "        if not api_key_configured:\n",
        "             print(\"(!) Error CRÍTICO: La API Key de Gemini no está configurada.\")\n",
        "        else:\n",
        "             # --- Nuevo Prompt con Tarea de Segmentación ---\n",
        "             prompt_segmentacion_y_meta_cot = f\"\"\"\n",
        "Contexto: Estoy creando una visualización semántica interactiva para el siguiente texto (que puede ser una frase, párrafo o estrofa). Necesito identificar sus frases/unidades principales y obtener un resumen de su análisis lingüístico previo.\n",
        "\n",
        "Texto Original Completo:\n",
        "'''\n",
        "{frase_seleccionada}\n",
        "'''\n",
        "\n",
        "Análisis Lingüístico Previo (CoT Original extraído de un análisis anterior):\n",
        "--- CoT Original ---\n",
        "{cot_original if pd.notna(cot_original) else 'No disponible'}\n",
        "--- Fin CoT Original ---\n",
        "\n",
        "Datos Estructurados Adicionales (extraídos de un JSON del análisis anterior, si estaban disponibles y eran válidos):\n",
        "--- JSON Parseado ---\n",
        "{json.dumps(parsed_json, indent=2, ensure_ascii=False) if parsed_json else 'JSON no disponible, inválido, o contenía un error.'}\n",
        "{f' (Error al parsear JSON original: {json_parse_error})' if json_parse_error else ''}\n",
        "--- Fin JSON Parseado ---\n",
        "\n",
        "Tarea Principal (Realiza en este orden):\n",
        "1.  **Segmentación en Unidades:** Basándote en el Texto Original y el CoT, identifica y lista las frases gramaticales completas o unidades semánticas principales dentro del texto. Si el texto es claramente una sola unidad/frase, indícalo explícitamente como \"1. Unidad Única: [texto completo]\". Si hay múltiples unidades, numéralas (1. [Texto Unidad 1], 2. [Texto Unidad 2], ...). Sé preciso al extraer el texto de cada unidad.\n",
        "2.  **Meta-Análisis CoT Conciso:** Después de la lista de segmentación, añade una línea separadora \"--- Meta-Análisis ---\" y luego genera un resumen (máximo 3-4 puntos clave) enfocado en aspectos semánticos/contextuales relevantes para la visualización (Naturaleza principal, Ambigüedad, Complejidad/Características, Conclusión Semántica). Basa este resumen SÓLO en el CoT Original y el JSON proporcionado.\n",
        "3.  **Palabras unidas en sentido figurado:** Después del Meta-Análisis, y considerando también el CoT original, revisa si el texto tiene predominantemente un caracter literario, poético, musical, etc. Si es así, entonces menciona casos significativos de asociación no literal, más figurada, de palabras y frases si aplica.\n",
        "**Instrucciones de Formato:**\n",
        "*   Primero, la lista numerada de unidades segmentadas (o la indicación de Unidad Única).\n",
        "*   Luego, la línea separadora \"--- Meta-Análisis ---\".\n",
        "*   Finalmente, el Meta-Análisis CoT en puntos numerados o con viñetas, incluyendo las palabras y frases unidas en sentido figurado si es que aplica.\n",
        "\n",
        "**Ejemplo de Salida Esperada (si hay múltiples unidades):**\n",
        "1. Texto de la primera frase o unidad detectada.\n",
        "2. Texto de la segunda frase o unidad detectada.\n",
        "--- Meta-Análisis ---\n",
        "*   Naturaleza: [Resumen]\n",
        "*   Ambigüedad: [Resumen]\n",
        "*   Complejidad: [Resumen]\n",
        "*   Revisión crítica: [Resumen]\n",
        "\n",
        "**Ejemplo de Salida Esperada (si es una sola unidad):**\n",
        "1. Unidad Única: [Texto completo original]\n",
        "--- Meta-Análisis ---\n",
        "*   Naturaleza: [Resumen]\n",
        "*   Ambigüedad: [Resumen]\n",
        "*   Complejidad: [Resumen]\n",
        "*   Revisión Crítica: [Resumen]\n",
        "\n",
        "**INICIA LA SALIDA:**\n",
        "\"\"\"\n",
        "\n",
        "             try:\n",
        "                 print(f\"-> Inicializando modelo LLM: '{LLM_MODEL_NAME}'...\")\n",
        "                 model_llm = genai.GenerativeModel(LLM_MODEL_NAME)\n",
        "                 generation_config = genai.types.GenerationConfig(temperature=0.2)\n",
        "\n",
        "                 print(\"-> Generando Segmentación y Meta-CoT (esto puede tardar)...\")\n",
        "                 response = model_llm.generate_content(\n",
        "                     prompt_segmentacion_y_meta_cot,\n",
        "                     generation_config=generation_config\n",
        "                 )\n",
        "                 respuesta_completa_llm = response.text\n",
        "\n",
        "                 # --- 3.4 Procesar la Respuesta del LLM ---\n",
        "                 print(\"\\n--- 3.4 Procesando la respuesta del LLM ---\")\n",
        "                 segmentacion_str = \"\"\n",
        "                 meta_cot_resumen_temp = \"\" # Usar temporal para evitar sobreescribir default\n",
        "\n",
        "                 # Buscar el separador\n",
        "                 separador = \"--- Meta-Análisis ---\"\n",
        "                 partes = respuesta_completa_llm.split(separador, 1) # Dividir solo en el primer separador\n",
        "\n",
        "                 if len(partes) == 2:\n",
        "                     segmentacion_str = partes[0].strip()\n",
        "                     meta_cot_resumen_temp = partes[1].strip()\n",
        "                     print(\"-> Separador encontrado. Extrayendo Segmentación y Meta-Análisis.\")\n",
        "                 else:\n",
        "                     # Si no encontró el separador, asumir que toda la respuesta es el Meta-CoT\n",
        "                     # y que no pudo segmentar o lo indicó dentro del texto.\n",
        "                     print(\"(!) Advertencia: No se encontró el separador '--- Meta-Análisis ---' en la respuesta.\")\n",
        "                     print(\"   Asumiendo que la respuesta completa es el Meta-Análisis o incluye la segmentación.\")\n",
        "                     segmentacion_str = respuesta_completa_llm # Guardar todo por si acaso\n",
        "                     meta_cot_resumen_temp = respuesta_completa_llm # O asignar solo una parte si se prefiere\n",
        "\n",
        "                 # Extraer las unidades de la parte de segmentación\n",
        "                 unidades_extraidas_temp = []\n",
        "                 # Usar regex para encontrar líneas numeradas al inicio\n",
        "                 # Ajusta la regex si el formato de salida del LLM varía\n",
        "                 matches = re.findall(r\"^\\s*\\d+\\.\\s*(.*)\", segmentacion_str, re.MULTILINE)\n",
        "                 if matches:\n",
        "                     for match in matches:\n",
        "                         # Comprobar si es la indicación de unidad única\n",
        "                         if match.lower().startswith(\"unidad única:\"):\n",
        "                              texto_unidad = match[len(\"unidad única:\"):].strip()\n",
        "                              # Podríamos decidir añadir el texto completo o la frase seleccionada\n",
        "                              unidades_extraidas_temp.append(frase_seleccionada) # Añadir el original completo\n",
        "                              print(f\"   - Detectada indicación de Unidad Única.\")\n",
        "                              break # Salir si es unidad única\n",
        "                         else:\n",
        "                              unidades_extraidas_temp.append(match.strip())\n",
        "                     print(f\"   - Extraídas {len(unidades_extraidas_temp)} unidades/frases de la segmentación.\")\n",
        "                 else:\n",
        "                      print(\"   (!) No se encontraron líneas numeradas claras en la sección de segmentación.\")\n",
        "                      # Si no hay líneas numeradas, podría ser una sola unidad no marcada explícitamente\n",
        "                      # o el LLM no siguió el formato. Como fallback, usar la frase original.\n",
        "                      if len(unidades_extraidas_temp) == 0:\n",
        "                           print(\"      -> Asumiendo una única unidad (el texto completo).\")\n",
        "                           unidades_extraidas_temp.append(frase_seleccionada)\n",
        "\n",
        "                 # Asignar a las variables finales\n",
        "                 lista_unidades_detectadas = unidades_extraidas_temp\n",
        "                 meta_cot_resumen = meta_cot_resumen_temp if meta_cot_resumen_temp else \"(Meta-Análisis no extraído)\"\n",
        "\n",
        "\n",
        "                 # --- 3.5 Mostrar Resultados ---\n",
        "                 print(\"\\n\" + \"=\"*70)\n",
        "                 print(\"Resultados del Chunk 3:\")\n",
        "                 print(\"=\"*70)\n",
        "                 print(\"Segmentación Detectada:\")\n",
        "                 print(\"-\"*70)\n",
        "                 if lista_unidades_detectadas:\n",
        "                     for i, unidad in enumerate(lista_unidades_detectadas):\n",
        "                         print(f\"{i+1}. {textwrap.fill(unidad, width=80, subsequent_indent='   ')}\")\n",
        "                 else:\n",
        "                     print(\"(No se detectaron unidades separadas)\")\n",
        "\n",
        "                 print(\"\\n\" + \"-\"*70)\n",
        "                 print(\"Meta-Análisis CoT (Resumen):\")\n",
        "                 print(\"-\"*70)\n",
        "                 # Usar display(Markdown(...)) para el resumen formateado\n",
        "                 from IPython.display import display, Markdown\n",
        "                 display(Markdown(meta_cot_resumen))\n",
        "                 print(\"=\"*70)\n",
        "\n",
        "\n",
        "             except Exception as e:\n",
        "                 print(f\"(!) Error durante la generación o procesamiento con LLM '{LLM_MODEL_NAME}': {e}\")\n",
        "                 # Guardar error en las variables para saber que falló\n",
        "                 lista_unidades_detectadas = []\n",
        "                 meta_cot_resumen = f\"Error al generar/procesar: {e}\"\n",
        "\n",
        "    # ... (Manejo de errores para IndexError y otros al buscar la fila) ...\n",
        "    except IndexError:\n",
        "        print(f\"(!) Error: No se encontró fila para: '{frase_seleccionada}'\")\n",
        "    except Exception as e:\n",
        "        print(f\"(!) Error inesperado al procesar fila: {e}\")\n",
        "\n",
        "# --- Fin Chunk 3 (Modificado) ---\n",
        "if 'lista_unidades_detectadas' not in globals(): lista_unidades_detectadas = [] # Asegurar que exista\n",
        "if 'meta_cot_resumen' not in globals(): meta_cot_resumen = \"(No disponible)\" # Asegurar que exista\n",
        "\n",
        "print(f\"\\n--- Fin del Proceso del Chunk 3 Modificado (Detectadas {len(lista_unidades_detectadas)} unidades) ---\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 783
        },
        "id": "fmbsADOUdBmx",
        "outputId": "cbe3107b-424c-4229-ec26-b4fffba44918",
        "cellView": "form"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- 3.1 Recuperando datos de la frase/texto seleccionado ---\n",
            "-> Texto seleccionado: 'Para realizar la configuración óptima del dispositivo, asegúrese de verificar que los puertos [...]'\n",
            "-> Fila de datos encontrada.\n",
            "\n",
            "--- 3.2 Intentando parsear la respuesta JSON original ---\n",
            "-> JSON parseado correctamente.\n",
            "\n",
            "--- 3.3 Preparando y generando Segmentación y Meta-Análisis CoT ---\n",
            "-> Inicializando modelo LLM: 'gemini-1.5-flash'...\n",
            "-> Generando Segmentación y Meta-CoT (esto puede tardar)...\n",
            "\n",
            "--- 3.4 Procesando la respuesta del LLM ---\n",
            "-> Separador encontrado. Extrayendo Segmentación y Meta-Análisis.\n",
            "   - Extraídas 2 unidades/frases de la segmentación.\n",
            "\n",
            "======================================================================\n",
            "Resultados del Chunk 3:\n",
            "======================================================================\n",
            "Segmentación Detectada:\n",
            "----------------------------------------------------------------------\n",
            "1. Para realizar la configuración óptima del dispositivo, asegúrese de verificar\n",
            "   que los puertos de entrada estén correctamente alineados con los conectores\n",
            "   del cable HDMI.\n",
            "2. los cuales suelen ubicarse en la parte posterior según el modelo adquirido,\n",
            "   evitando así posibles fallos de transmisión de datos durante el proceso de\n",
            "   sincronización.\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "Meta-Análisis CoT (Resumen):\n",
            "----------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "* Naturaleza: Instrucción técnica formal para la configuración de un dispositivo electrónico.  El texto pertenece a un manual de usuario o guía de configuración, con el objetivo de guiar al usuario en la conexión correcta del dispositivo.\n* Ambigüedad: Ausencia de ambigüedad significativa. El significado es claro y conciso, dirigido a evitar problemas de conexión.\n* Complejidad:  Estructura gramatical compleja, con una oración principal y una subordinada (que a su vez contiene una oración relativa).  Sin embargo, la complejidad gramatical no afecta la claridad del mensaje.  El texto utiliza vocabulario técnico específico del ámbito de la electrónica.\n* Conclusión Semántica: El texto cumple eficazmente su función instructiva, proporcionando instrucciones precisas y concisas para evitar fallos en la conexión del dispositivo.\n\n\n* Palabras unidas en sentido figurado: No hay palabras o frases unidas en sentido figurado. El lenguaje es completamente literal y técnico.  No presenta características literarias, poéticas o musicales."
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "\n",
            "--- Fin del Proceso del Chunk 3 Modificado (Detectadas 2 unidades) ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 4 (Revisado v3): Preparación y Generación de Embeddings (Palabras con Detalles JSON y Unidades)\n",
        "\n",
        "import google.generativeai as genai\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import json\n",
        "import time\n",
        "import textwrap\n",
        "\n",
        "# --- Reutilizar Función de Embedding ---\n",
        "# (Asumiendo que la función get_embeddings_batch_local está definida arriba o en celda previa)\n",
        "# ... (código de la función get_embeddings_batch_local) ...\n",
        "def get_embeddings_batch_local(texts, model_name, task_type=\"RETRIEVAL_DOCUMENT\", max_retries=2, initial_delay=2):\n",
        "    # ... (código completo de la función) ...\n",
        "    embeddings_list = [None] * len(texts); # ... (resto del código de la función) ...\n",
        "    if not texts: print(\"-> No hay textos.\"); return embeddings_list # ...\n",
        "    if 'api_key_configured' not in globals() or not api_key_configured: print(\"(!) Error API Key.\"); return embeddings_list # ...\n",
        "    print(f\"-> Solicitando embeddings para {len(texts)} textos ({model_name}, {task_type})...\"); # ...\n",
        "    current_texts = list(texts); indices = list(range(len(texts))); batch_size = 100; all_results = {}; # ...\n",
        "    for i in range(0, len(current_texts), batch_size): # ...\n",
        "        batch_texts = current_texts[i:i + batch_size]; batch_indices = indices[i:i + batch_size]; # ...\n",
        "        print(f\"   Procesando batch {i//batch_size + 1} (tamaño: {len(batch_texts)})...\"); # ...\n",
        "        for attempt in range(max_retries + 1): # ...\n",
        "            try: # ...\n",
        "                result = genai.embed_content(model=f\"models/{model_name}\", content=batch_texts, task_type=task_type); # ...\n",
        "                if 'embedding' in result and len(result['embedding']) == len(batch_texts): # ...\n",
        "                    print(f\"      -> Embeddings OK (intento {attempt + 1}).\"); # ...\n",
        "                    for j, emb in enumerate(result['embedding']): all_results[batch_indices[j]] = list(emb); # ...\n",
        "                    break; # ...\n",
        "            except Exception as e: # ...\n",
        "                print(f\"   (!) Error API (Batch {i//batch_size + 1}, Intento {attempt + 1}): {e}\"); # ...\n",
        "                error_str = str(e).lower(); # ...\n",
        "                if \"model not found\" in error_str or \"api key not valid\" in error_str or \"permission denied\" in error_str or \"invalid argument\" in error_str: print(\"      -> Error definitivo.\"); break; # ...\n",
        "                if attempt < max_retries: delay = initial_delay * (2 ** attempt); print(f\"      -> Reintentando en {delay} seg...\"); time.sleep(delay); # ...\n",
        "                else: print(f\"      -> Máximo reintentos.\"); break; # ...\n",
        "    for original_idx in range(len(texts)): # ...\n",
        "        if original_idx in all_results: embeddings_list[original_idx] = all_results[original_idx]; # ...\n",
        "    num_exitosos = sum(1 for emb in embeddings_list if emb is not None); # ...\n",
        "    print(f\"-> Proceso finalizado. {num_exitosos}/{len(texts)} embeddings generados.\"); # ...\n",
        "    if num_exitosos < len(texts): print(f\"   (!) {len(texts) - num_exitosos} texto(s) fallaron.\"); # ...\n",
        "    return embeddings_list; # ...\n",
        "\n",
        "# --- 4.1 Recuperar Datos Necesarios ---\n",
        "print(\"--- 4.1 Recuperando datos (JSON, Unidades, Texto Completo) ---\")\n",
        "# ... (código de verificación de variables sin cambios) ...\n",
        "variables_ok = True # ... (resto del código de verificación) ...\n",
        "if 'frase_seleccionada' not in globals(): print(\"(!) Error: Falta 'frase_seleccionada'.\"); variables_ok = False # ...\n",
        "if 'parsed_json' not in globals(): print(\"(!) Error: Falta 'parsed_json'.\") # ... (puede ser None) ...\n",
        "if 'lista_unidades_detectadas' not in globals(): print(\"(!) Error: Falta 'lista_unidades_detectadas'.\"); variables_ok = False # ...\n",
        "if 'columna_respuesta_json' not in globals(): print(\"(!) Error: Falta 'columna_respuesta_json'.\"); variables_ok = False # ...\n",
        "\n",
        "palabras_info_detallada = [] # <--- CAMBIO: Guardará diccionarios con TODOS los detalles\n",
        "textos_unidades = []\n",
        "texto_completo = None\n",
        "\n",
        "if variables_ok:\n",
        "    texto_completo = frase_seleccionada\n",
        "    textos_unidades = lista_unidades_detectadas if isinstance(lista_unidades_detectadas, list) else []\n",
        "\n",
        "    # --- 4.2 Extraer Información DETALLADA de Palabras del JSON --- ## MODIFICADO ##\n",
        "    print(\"\\n--- 4.2 Extrayendo información DETALLADA de palabras del JSON ---\")\n",
        "    campos_posibles = set() # Para rastrear todos los campos encontrados\n",
        "\n",
        "    if isinstance(parsed_json, list):\n",
        "        print(f\"-> JSON es lista con {len(parsed_json)} elementos.\")\n",
        "        for index, item in enumerate(parsed_json):\n",
        "            if isinstance(item, dict):\n",
        "                palabra_data = {'indice': index} # Guardar índice original del JSON\n",
        "                # Extraer todos los campos presentes en el item del JSON\n",
        "                for key, value in item.items():\n",
        "                    # Guardamos el valor si no es None y (si es string/lista) no está vacío\n",
        "                    # Excepciones: palabra_analizada y categoria se guardan aunque estén vacíos (para asegurar existencia)\n",
        "                    if key in ['palabra_analizada', 'categoria'] or \\\n",
        "                       (value is not None and not isinstance(value, (str, list)) or value): # Guarda si no es None Y (no es str/list O no está vacío)\n",
        "                         palabra_data[key] = value\n",
        "                         campos_posibles.add(key)\n",
        "\n",
        "                # Asegurar campos mínimos y renombrar 'palabra' para consistencia\n",
        "                if 'palabra_analizada' not in palabra_data:\n",
        "                     palabra_data['texto'] = item.get('texto', f'Palabra_{index}_?') # Usar 'texto' como nombre estándar\n",
        "                     if palabra_data['texto'] == f'Palabra_{index}_?': print(f\"   (!) Advertencia: JSON[{index}] sin 'palabra_analizada'/'text'.\")\n",
        "                else:\n",
        "                     palabra_data['texto'] = palabra_data.pop('palabra_analizada') # Renombrar a 'texto'\n",
        "\n",
        "                if 'categoria' not in palabra_data:\n",
        "                     palabra_data['categoria'] = 'desconocida'\n",
        "\n",
        "                palabras_info_detallada.append(palabra_data) # <--- Guardar en la nueva lista\n",
        "            else:\n",
        "                 print(f\"   (!) Advertencia: JSON[{index}] no es diccionario.\")\n",
        "        print(f\"-> Extraídos datos detallados para {len(palabras_info_detallada)} palabras.\")\n",
        "        print(f\"-> Campos JSON encontrados: {sorted(list(campos_posibles))}\")\n",
        "        if palabras_info_detallada:\n",
        "            # Mostrar llaves del primer diccionario como ejemplo\n",
        "            print(f\"   Ejemplo campos Palabra 0: {list(palabras_info_detallada[0].keys())}\")\n",
        "    elif parsed_json is None: print(\"-> JSON no disponible/inválido.\")\n",
        "    else: print(f\"(!) Error: JSON parseado no es lista (tipo: {type(parsed_json)}).\")\n",
        "\n",
        "else:\n",
        "     print(\"(!) No se pueden continuar los preparativos.\")\n",
        "\n",
        "# --- 4.3 Preparar Lista Unificada de Textos para Embedding ---\n",
        "print(\"\\n--- 4.3 Preparando lista unificada de textos ---\")\n",
        "lista_unificada_textos = []\n",
        "lista_tipos_texto = []\n",
        "lista_indices_ref = []\n",
        "lista_categorias_temp = [] # Lista temporal solo para palabras\n",
        "\n",
        "if variables_ok:\n",
        "    # 1. Añadir Palabras (solo el texto)\n",
        "    if palabras_info_detallada: # <--- Usar la nueva lista\n",
        "        print(f\"-> Añadiendo texto de {len(palabras_info_detallada)} palabras...\")\n",
        "        for info in palabras_info_detallada:\n",
        "            lista_unificada_textos.append(info.get('texto','?')) # Añadir el texto de la palabra\n",
        "            lista_tipos_texto.append(\"Palabra\")\n",
        "            lista_indices_ref.append(info.get('indice', -1)) # Índice original del JSON\n",
        "            lista_categorias_temp.append(info.get('categoria', 'desconocida')) # Guardar categoría temporalmente\n",
        "    else:\n",
        "         print(\"-> No se añadieron palabras.\")\n",
        "\n",
        "    # 2. Añadir Unidades Detectadas\n",
        "    # ... (código para añadir unidades a lista_unificada_textos y lista_tipos_texto sin cambios) ...\n",
        "    num_unidades_anadidas = 0\n",
        "    if len(textos_unidades) > 1:\n",
        "        print(f\"-> Añadiendo {len(textos_unidades)} unidades detectadas...\")\n",
        "        for idx, unidad_texto in enumerate(textos_unidades):\n",
        "             if unidad_texto != texto_completo:\n",
        "                lista_unificada_textos.append(unidad_texto); lista_tipos_texto.append(\"Unidad\"); lista_indices_ref.append(idx + 1); lista_categorias_temp.append(None); num_unidades_anadidas += 1\n",
        "             else: print(f\"   (Omitiendo unidad {idx+1})\")\n",
        "        print(f\"   -> {num_unidades_anadidas} unidades añadidas.\")\n",
        "    # ... (manejo caso 1 unidad o 0 unidades) ...\n",
        "    elif len(textos_unidades) == 1: print(\"-> Solo 1 unidad detectada, se usará TextoCompleto.\")\n",
        "    else: print(\"-> No se detectaron unidades separadas.\")\n",
        "\n",
        "    # 3. Añadir Texto Completo Original\n",
        "    # ... (código para añadir texto_completo sin cambios) ...\n",
        "    if texto_completo:\n",
        "        print(\"-> Añadiendo texto completo...\"); lista_unificada_textos.append(texto_completo); lista_tipos_texto.append(\"TextoCompleto\"); lista_indices_ref.append(0); lista_categorias_temp.append(None)\n",
        "    else: print(\"(!) No se pudo añadir texto completo.\")\n",
        "\n",
        "    print(f\"-> Total textos unificados para embeddear: {len(lista_unificada_textos)}\")\n",
        "\n",
        "else:\n",
        "     print(\"(!) No se preparó la lista unificada.\")\n",
        "\n",
        "\n",
        "# --- 4.4 Generar Embeddings para la Lista Unificada ---\n",
        "print(\"\\n--- 4.4 Generando embeddings para lista unificada ---\")\n",
        "# ... (código para determinar task_type_auto sin cambios) ...\n",
        "num_palabras = sum(1 for t in lista_tipos_texto if t == 'Palabra'); num_otros = len(lista_unificada_textos) - num_palabras; task_type_auto = \"SEMANTIC_SIMILARITY\" if num_palabras > num_otros else \"RETRIEVAL_DOCUMENT\"; print(f\"   (Usando task_type='{task_type_auto}')\")\n",
        "\n",
        "lista_embeddings_unificada = get_embeddings_batch_local(\n",
        "    lista_unificada_textos, model_name=EMBEDDING_MODEL_NAME, task_type=task_type_auto\n",
        ")\n",
        "\n",
        "# --- 4.5 Estructurar Resultados Combinados (con Detalles JSON) --- ## MODIFICADO ##\n",
        "print(\"\\n--- 4.5 Estructurando resultados combinados (con detalles JSON) ---\")\n",
        "resultados_combinados = []\n",
        "num_embeddings_fallidos_total = 0\n",
        "\n",
        "if len(lista_unificada_textos) == len(lista_embeddings_unificada):\n",
        "    palabra_info_idx = 0 # Contador para acceder a palabras_info_detallada\n",
        "    for i in range(len(lista_unificada_textos)):\n",
        "        embedding = lista_embeddings_unificada[i]\n",
        "        if embedding is None:\n",
        "             num_embeddings_fallidos_total += 1\n",
        "             print(f\"  (!) Falló embedding para: ({lista_tipos_texto[i]} {lista_indices_ref[i]}) '{textwrap.shorten(lista_unificada_textos[i], 60)}'\")\n",
        "             continue # Saltar si no hay embedding\n",
        "\n",
        "        # Crear registro base\n",
        "        record = {\n",
        "            \"texto\": lista_unificada_textos[i],\n",
        "            \"tipo\": lista_tipos_texto[i],\n",
        "            \"indice_ref\": lista_indices_ref[i],\n",
        "            \"embedding_vector\": np.array(embedding)\n",
        "        }\n",
        "\n",
        "        # Si es una palabra, añadir TODOS los detalles de palabras_info_detallada\n",
        "        if record['tipo'] == 'Palabra':\n",
        "            if palabra_info_idx < len(palabras_info_detallada):\n",
        "                 # Fusionar el record base con el diccionario de detalles de la palabra\n",
        "                 # Dando prioridad a los valores ya en record (texto, tipo, indice_ref, embedding)\n",
        "                 # y añadiendo los demás del diccionario de detalles\n",
        "                 detalles_palabra = palabras_info_detallada[palabra_info_idx]\n",
        "                 # Crear un nuevo diccionario para evitar modificar el original\n",
        "                 record_completo = record.copy()\n",
        "                 # Añadir detalles, evitando sobreescribir claves base si ya existen en detalles_palabra\n",
        "                 for key, value in detalles_palabra.items():\n",
        "                      if key not in record_completo: # Añadir solo si no es una clave base ya presente\n",
        "                           record_completo[key] = value\n",
        "                 # Asegurar que 'categoria' esté presente, usando la de detalles si existe\n",
        "                 record_completo['categoria'] = detalles_palabra.get('categoria', 'desconocida')\n",
        "                 record = record_completo # Usar el registro completo\n",
        "                 palabra_info_idx += 1\n",
        "            else:\n",
        "                 print(f\"(!) Advertencia: Discrepancia mapeo embedding palabra {i}.\")\n",
        "                 record['categoria'] = 'error_mapeo'\n",
        "\n",
        "        # Si es Unidad o TextoCompleto, asegurar que 'categoria' sea None\n",
        "        elif record['tipo'] in ['Unidad', 'TextoCompleto']:\n",
        "             record['categoria'] = None\n",
        "\n",
        "        resultados_combinados.append(record)\n",
        "\n",
        "    if resultados_combinados:\n",
        "        # Crear DataFrame a partir de la lista de diccionarios\n",
        "        df_embeddings_combinado = pd.DataFrame(resultados_combinados)\n",
        "\n",
        "        # Rellenar posibles NaNs en columnas JSON (opcional, pero puede ayudar)\n",
        "        # Identificar columnas que no sean las base o el vector\n",
        "        columnas_base = ['texto', 'tipo', 'indice_ref', 'embedding_vector', 'categoria', 'indice']\n",
        "        columnas_json = [col for col in df_embeddings_combinado.columns if col not in columnas_base]\n",
        "        # df_embeddings_combinado[columnas_json] = df_embeddings_combinado[columnas_json].fillna(\"N/A\") # Llenar con string \"N/A\"\n",
        "\n",
        "        print(f\"\\n-> Creado DataFrame 'df_embeddings_combinado' con {len(df_embeddings_combinado)} elementos válidos.\")\n",
        "        print(f\"   Columnas: {list(df_embeddings_combinado.columns)}\")\n",
        "    # ... (resto del código de manejo de errores y df vacío) ...\n",
        "\n",
        "else:\n",
        "    # ... (código de manejo de discrepancia o fallo total) ...\n",
        "    print(f\"(!) Discrepancia textos/embeddings o fallo total.\")\n",
        "    df_embeddings_combinado = pd.DataFrame()\n",
        "\n",
        "# --- Fin Chunk 4 (Revisado v3) ---\n",
        "print(f\"\\n--- Fin del Proceso del Chunk 4 Revisado v3 ({num_embeddings_fallidos_total} fallos) ---\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 537
        },
        "collapsed": true,
        "cellView": "form",
        "id": "mgYbKPA4dhOg",
        "outputId": "76c51457-a770-45d0-8a5f-f872665de6d8"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- 4.1 Recuperando datos (JSON, Unidades, Texto Completo) ---\n",
            "\n",
            "--- 4.2 Extrayendo información DETALLADA de palabras del JSON ---\n",
            "-> JSON es lista con 54 elementos.\n",
            "-> Extraídos datos detallados para 54 palabras.\n",
            "-> Campos JSON encontrados: ['aumentativo_comun', 'caso', 'categoria', 'definicion_contextual', 'definicion_funcion', 'definicion_general', 'diminutivo_comun', 'ejemplos_uso', 'funcion', 'genero', 'gerundio', 'grado', 'infinitivo', 'lemma', 'modifica_a', 'modo', 'numero', 'palabra_analizada', 'participio', 'persona', 'referente_aproximado', 'subtipo', 'tiempo', 'tipo', 'tonicidad', 'transitividad', 'usos_comunes']\n",
            "   Ejemplo campos Palabra 0: ['indice', 'categoria', 'tipo', 'usos_comunes', 'ejemplos_uso', 'texto']\n",
            "\n",
            "--- 4.3 Preparando lista unificada de textos ---\n",
            "-> Añadiendo texto de 54 palabras...\n",
            "-> Añadiendo 2 unidades detectadas...\n",
            "   -> 2 unidades añadidas.\n",
            "-> Añadiendo texto completo...\n",
            "-> Total textos unificados para embeddear: 57\n",
            "\n",
            "--- 4.4 Generando embeddings para lista unificada ---\n",
            "   (Usando task_type='SEMANTIC_SIMILARITY')\n",
            "-> Solicitando embeddings para 57 textos (embedding-001, SEMANTIC_SIMILARITY)...\n",
            "   Procesando batch 1 (tamaño: 57)...\n",
            "      -> Embeddings OK (intento 1).\n",
            "-> Proceso finalizado. 57/57 embeddings generados.\n",
            "\n",
            "--- 4.5 Estructurando resultados combinados (con detalles JSON) ---\n",
            "\n",
            "-> Creado DataFrame 'df_embeddings_combinado' con 57 elementos válidos.\n",
            "   Columnas: ['texto', 'tipo', 'indice_ref', 'embedding_vector', 'indice', 'categoria', 'usos_comunes', 'ejemplos_uso', 'infinitivo', 'modo', 'participio', 'gerundio', 'transitividad', 'definicion_general', 'subtipo', 'genero', 'numero', 'definicion_funcion', 'lemma', 'diminutivo_comun', 'aumentativo_comun', 'definicion_contextual', 'grado', 'modifica_a', 'funcion', 'persona', 'caso', 'tonicidad', 'referente_aproximado', 'tiempo']\n",
            "\n",
            "--- Fin del Proceso del Chunk 4 Revisado v3 (0 fallos) ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 5 (Revisado v2): Reducción de Dimensionalidad para Embeddings Combinados\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import umap\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# --- 5.1 Preparar Datos Combinados para Reducción ---\n",
        "print(\"--- 5.1 Preparando embeddings COMBINADOS (Palabras, Unidades, Texto Completo) ---\")\n",
        "\n",
        "embeddings_2d_umap_combinado = None\n",
        "embeddings_2d_pca_combinado = None\n",
        "reduction_combinada_successful = False # Bandera para este chunk\n",
        "\n",
        "# Verificar si tenemos el DataFrame combinado del Chunk 4 (Revisado v2)\n",
        "if 'df_embeddings_combinado' in globals() and isinstance(df_embeddings_combinado, pd.DataFrame) and not df_embeddings_combinado.empty:\n",
        "    if 'embedding_vector' in df_embeddings_combinado.columns:\n",
        "        # Extraer solo los vectores de embedding válidos (no None)\n",
        "        valid_embeddings_series = df_embeddings_combinado['embedding_vector'].dropna()\n",
        "\n",
        "        if not valid_embeddings_series.empty:\n",
        "            embedding_vectors_list_combinado = valid_embeddings_series.tolist()\n",
        "\n",
        "            # Apilar los vectores en un único array NumPy 2D\n",
        "            try:\n",
        "                # Asegurarse de que todos los elementos son arrays NumPy antes de apilar\n",
        "                valid_vectors_combinado = [vec for vec in embedding_vectors_list_combinado if isinstance(vec, np.ndarray)]\n",
        "                if len(valid_vectors_combinado) != len(embedding_vectors_list_combinado):\n",
        "                     print(f\"(!) Advertencia: Se descartaron {len(embedding_vectors_list_combinado) - len(valid_vectors_combinado)} elementos no válidos antes de apilar.\")\n",
        "\n",
        "                if not valid_vectors_combinado:\n",
        "                     print(\"(!) Error: No hay vectores de embedding válidos para apilar.\")\n",
        "                     reduction_combinada_possible = False\n",
        "                else:\n",
        "                    embeddings_array_combinado = np.stack(valid_vectors_combinado, axis=0)\n",
        "                    print(f\"-> Array de embeddings combinados preparado. Forma: {embeddings_array_combinado.shape}\")\n",
        "\n",
        "                    # Verificar si tenemos al menos 2 puntos para reducir\n",
        "                    if embeddings_array_combinado.shape[0] >= 2:\n",
        "                        reduction_combinada_possible = True\n",
        "                        print(f\"-> Se puede realizar reducción para {embeddings_array_combinado.shape[0]} elementos combinados.\")\n",
        "                    else:\n",
        "                        print(\"-> Solo hay 1 elemento con embedding válido. No se necesita reducción.\")\n",
        "                        reduction_combinada_possible = False\n",
        "                        # Asignar coordenadas (0,0) para el único punto\n",
        "                        embeddings_2d_umap_combinado = np.array([[0.0, 0.0]])\n",
        "                        embeddings_2d_pca_combinado = np.array([[0.0, 0.0]])\n",
        "                        reduction_combinada_successful = True # Consideramos éxito tener las coords\n",
        "\n",
        "            except ValueError as e:\n",
        "                 print(f\"(!) Error al apilar los vectores de embedding combinados: {e}\")\n",
        "                 reduction_combinada_possible = False\n",
        "            except Exception as e:\n",
        "                 print(f\"(!) Error inesperado al preparar el array combinado: {e}\")\n",
        "                 reduction_combinada_possible = False\n",
        "\n",
        "        else: # Si después de dropna() no queda nada\n",
        "             print(\"(!) Error: No hay embeddings válidos en 'df_embeddings_combinado' después de eliminar Nulos.\")\n",
        "             reduction_combinada_possible = False\n",
        "    else:\n",
        "        print(\"(!) Error: La columna 'embedding_vector' no se encontró en 'df_embeddings_combinado'.\")\n",
        "        reduction_combinada_possible = False\n",
        "else:\n",
        "    print(\"(!) Error: El DataFrame 'df_embeddings_combinado' no existe o está vacío.\")\n",
        "    print(\"   Asegúrate de que el Chunk 4 (Revisado v2) se haya ejecutado correctamente.\")\n",
        "    reduction_combinada_possible = False\n",
        "\n",
        "# --- 5.2 Aplicar Reducción de Dimensionalidad (si es posible y necesario) ---\n",
        "if reduction_combinada_possible:\n",
        "    print(\"\\n--- 5.2 Aplicando Reducción de Dimensionalidad a embeddings combinados ---\")\n",
        "\n",
        "    # --- UMAP ---\n",
        "    print(\"   -> Calculando reducción combinada con UMAP...\")\n",
        "    try:\n",
        "        n_samples = embeddings_array_combinado.shape[0]\n",
        "        n_neighbors_umap = min(15, max(2, n_samples - 1)) if n_samples > 2 else 1\n",
        "        print(f\"      (Usando n_neighbors={n_neighbors_umap})\")\n",
        "\n",
        "        umap_reducer_combinado = umap.UMAP(\n",
        "            n_components=2, n_neighbors=n_neighbors_umap, min_dist=0.1,\n",
        "            metric='cosine', random_state=42, n_jobs=1\n",
        "        )\n",
        "        embeddings_2d_umap_combinado = umap_reducer_combinado.fit_transform(embeddings_array_combinado)\n",
        "        print(f\"      -> Reducción UMAP combinada completada. Forma: {embeddings_2d_umap_combinado.shape}\")\n",
        "        reduction_combinada_successful = True\n",
        "    except Exception as e:\n",
        "        print(f\"   (!) Error durante la reducción UMAP combinada: {e}\")\n",
        "        embeddings_2d_umap_combinado = None\n",
        "        if not reduction_combinada_successful: print(\"      Intentando PCA como alternativa...\")\n",
        "\n",
        "\n",
        "    # --- PCA ---\n",
        "    print(\"\\n   -> Calculando reducción combinada con PCA...\")\n",
        "    try:\n",
        "        pca_reducer_combinado = PCA(n_components=2, random_state=42)\n",
        "        embeddings_2d_pca_combinado = pca_reducer_combinado.fit_transform(embeddings_array_combinado)\n",
        "        print(f\"      -> Reducción PCA combinada completada. Forma: {embeddings_2d_pca_combinado.shape}\")\n",
        "        if not reduction_combinada_successful: reduction_combinada_successful = True\n",
        "    except Exception as e:\n",
        "        print(f\"   (!) Error durante la reducción PCA combinada: {e}\")\n",
        "        embeddings_2d_pca_combinado = None\n",
        "\n",
        "\n",
        "# --- 5.3 Añadir Coordenadas al DataFrame Combinado ---\n",
        "# Asegurarse de que el DataFrame original exista para añadirle las columnas\n",
        "if 'df_embeddings_combinado' in globals() and isinstance(df_embeddings_combinado, pd.DataFrame) and not df_embeddings_combinado.empty:\n",
        "    if reduction_combinada_successful:\n",
        "        print(\"\\n--- 5.3 Añadiendo coordenadas 2D al DataFrame 'df_embeddings_combinado' ---\")\n",
        "\n",
        "        # Crear DataFrames temporales con las coordenadas y el índice original\n",
        "        # Esto es más seguro si hubo NaNs y se filtraron al crear embeddings_array_combinado\n",
        "        indices_validos = valid_embeddings_series.index # Índices de las filas con embeddings válidos\n",
        "\n",
        "        try:\n",
        "            # Añadir UMAP si se calcularon\n",
        "            if embeddings_2d_umap_combinado is not None and embeddings_2d_umap_combinado.shape[0] == len(indices_validos):\n",
        "                 df_coords_umap = pd.DataFrame(embeddings_2d_umap_combinado, columns=['umap_x', 'umap_y'], index=indices_validos)\n",
        "                 df_embeddings_combinado = df_embeddings_combinado.join(df_coords_umap)\n",
        "                 print(\"   -> Coordenadas UMAP (umap_x, umap_y) añadidas/actualizadas.\")\n",
        "            else:\n",
        "                 print(\"   (!) No se añadieron coordenadas UMAP (falló cálculo o forma/índices no coinciden).\")\n",
        "                 if 'umap_x' not in df_embeddings_combinado.columns: df_embeddings_combinado['umap_x'] = np.nan\n",
        "                 if 'umap_y' not in df_embeddings_combinado.columns: df_embeddings_combinado['umap_y'] = np.nan\n",
        "\n",
        "            # Añadir PCA si se calcularon\n",
        "            if embeddings_2d_pca_combinado is not None and embeddings_2d_pca_combinado.shape[0] == len(indices_validos):\n",
        "                 df_coords_pca = pd.DataFrame(embeddings_2d_pca_combinado, columns=['pca_x', 'pca_y'], index=indices_validos)\n",
        "                 df_embeddings_combinado = df_embeddings_combinado.join(df_coords_pca)\n",
        "                 print(\"   -> Coordenadas PCA (pca_x, pca_y) añadidas/actualizadas.\")\n",
        "            else:\n",
        "                 print(\"   (!) No se añadieron coordenadas PCA (falló cálculo o forma/índices no coinciden).\")\n",
        "                 if 'pca_x' not in df_embeddings_combinado.columns: df_embeddings_combinado['pca_x'] = np.nan\n",
        "                 if 'pca_y' not in df_embeddings_combinado.columns: df_embeddings_combinado['pca_y'] = np.nan\n",
        "\n",
        "            # Rellenar posibles NaNs introducidos por el join si alguna coordenada falló\n",
        "            # df_embeddings_combinado[['umap_x', 'umap_y', 'pca_x', 'pca_y']] = df_embeddings_combinado[['umap_x', 'umap_y', 'pca_x', 'pca_y']].fillna(0.0) # Opcional: rellenar con 0\n",
        "\n",
        "            # Mostrar ejemplo\n",
        "            # print(\"\\n   DataFrame 'df_embeddings_combinado' con coordenadas:\")\n",
        "            # print(df_embeddings_combinado[['texto', 'tipo', 'umap_x', 'umap_y', 'pca_x', 'pca_y']].head())\n",
        "\n",
        "        except Exception as e:\n",
        "              print(f\"(!) Error al añadir coordenadas al DataFrame combinado: {e}\")\n",
        "\n",
        "    else: # Si la reducción no fue exitosa pero el DataFrame existe\n",
        "         print(\"\\n--- 5.3 No se realizó o falló la reducción de dimensionalidad combinada ---\")\n",
        "         if 'umap_x' not in df_embeddings_combinado.columns: df_embeddings_combinado['umap_x'] = np.nan\n",
        "         if 'umap_y' not in df_embeddings_combinado.columns: df_embeddings_combinado['umap_y'] = np.nan\n",
        "         if 'pca_x' not in df_embeddings_combinado.columns: df_embeddings_combinado['pca_x'] = np.nan\n",
        "         if 'pca_y' not in df_embeddings_combinado.columns: df_embeddings_combinado['pca_y'] = np.nan\n",
        "         print(\"   -> Columnas de coordenadas añadidas como NaN.\")\n",
        "\n",
        "# --- Fin Chunk 5 (Revisado v2) ---\n",
        "print(\"\\n--- Fin del Proceso del Chunk 5 Revisado v2 ---\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "__y3mrGpeQw5",
        "outputId": "f0c687b8-d44a-4f29-9bc5-424a9749e46f"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- 5.1 Preparando embeddings COMBINADOS (Palabras, Unidades, Texto Completo) ---\n",
            "-> Array de embeddings combinados preparado. Forma: (57, 768)\n",
            "-> Se puede realizar reducción para 57 elementos combinados.\n",
            "\n",
            "--- 5.2 Aplicando Reducción de Dimensionalidad a embeddings combinados ---\n",
            "   -> Calculando reducción combinada con UMAP...\n",
            "      (Usando n_neighbors=15)\n",
            "      -> Reducción UMAP combinada completada. Forma: (57, 2)\n",
            "\n",
            "   -> Calculando reducción combinada con PCA...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
            "\n",
            "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      -> Reducción PCA combinada completada. Forma: (57, 2)\n",
            "\n",
            "--- 5.3 Añadiendo coordenadas 2D al DataFrame 'df_embeddings_combinado' ---\n",
            "   -> Coordenadas UMAP (umap_x, umap_y) añadidas/actualizadas.\n",
            "   -> Coordenadas PCA (pca_x, pca_y) añadidas/actualizadas.\n",
            "\n",
            "--- Fin del Proceso del Chunk 5 Revisado v2 ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 6 (Revisado v3): Creación del DataFrame Final con Tooltip Dinámico\n",
        "\n",
        "import pandas as pd\n",
        "import textwrap\n",
        "import numpy as np # Para isnan si fuera necesario\n",
        "\n",
        "# --- Función para formatear Tooltip ---\n",
        "def format_tooltip_details(row):\n",
        "    \"\"\"Formatea el tooltip HTML basado en la fila de datos.\"\"\"\n",
        "    if row.get('tipo') != 'Palabra':\n",
        "        # Tooltip simple para Unidad o TextoCompleto\n",
        "        # Mantener este simple por ahora, podríamos añadir más si es necesario\n",
        "        return f\"<b>Tipo:</b> {row.get('tipo', 'N/A')}<br><b>Texto:</b> {textwrap.shorten(str(row.get('texto','?')), width=60, placeholder='...')}\"\n",
        "\n",
        "    # --- Construir tooltip detallado para Palabras ---\n",
        "    details = []\n",
        "    # NO añadimos Categoría aquí, lo haremos en el hovertemplate\n",
        "\n",
        "    # --- Campos Comunes ---\n",
        "    # Usar <b> para las etiquetas\n",
        "    if pd.notna(row.get('lemma')): details.append(f\"<b>Lema:</b> {row['lemma']}\")\n",
        "    if pd.notna(row.get('genero')): details.append(f\"<b>Género:</b> {row['genero']}\")\n",
        "    if pd.notna(row.get('numero')): details.append(f\"<b>Número:</b> {row['numero']}\")\n",
        "    if pd.notna(row.get('tipo')) and row.get('tipo') != row.get('categoria'):\n",
        "         details.append(f\"<b>Tipo Espec.:</b> {row['tipo']}\")\n",
        "\n",
        "    # --- Campos de Verbos ---\n",
        "    if pd.notna(row.get('infinitivo')): details.append(f\"<b>Infinitivo:</b> {row['infinitivo']}\")\n",
        "    if pd.notna(row.get('modo')): details.append(f\"<b>Modo:</b> {row['modo']}\")\n",
        "    if pd.notna(row.get('tiempo')): details.append(f\"<b>Tiempo:</b> {row['tiempo']}\")\n",
        "    if pd.notna(row.get('persona')): details.append(f\"<b>Persona:</b> {row['persona']}\")\n",
        "    if pd.notna(row.get('participio')): details.append(f\"<b>Participio:</b> {row['participio']}\")\n",
        "    if pd.notna(row.get('gerundio')): details.append(f\"<b>Gerundio:</b> {row['gerundio']}\")\n",
        "    if pd.notna(row.get('transitividad')): details.append(f\"<b>Transitiv.:</b> {row['transitividad']}\")\n",
        "\n",
        "    # --- Campos de Adjetivos / Adverbios ---\n",
        "    if pd.notna(row.get('grado')): details.append(f\"<b>Grado:</b> {row['grado']}\")\n",
        "    if pd.notna(row.get('apocope')): details.append(f\"<b>Apócope:</b> {row['apocope']}\")\n",
        "\n",
        "    # --- Campos de Pronombres ---\n",
        "    if pd.notna(row.get('caso')): details.append(f\"<b>Caso:</b> {row['caso']}\")\n",
        "    if pd.notna(row.get('tonicidad')): details.append(f\"<b>Tonicidad:</b> {row['tonicidad']}\")\n",
        "    if pd.notna(row.get('referente_aproximado')): details.append(f\"<b>Referente:</b> {row['referente_aproximado']}\")\n",
        "\n",
        "    # --- Campos de Determinantes ---\n",
        "    if pd.notna(row.get('subtipo')) and row.get('categoria') == 'determinante':\n",
        "        details.append(f\"<b>Subtipo:</b> {row['subtipo']}\")\n",
        "    if pd.notna(row.get('distancia')): details.append(f\"<b>Distancia:</b> {row['distancia']}\")\n",
        "\n",
        "    # --- Campos de Sustantivos ---\n",
        "    if pd.notna(row.get('diminutivo_comun')): details.append(f\"<b>Diminutivo:</b> {row['diminutivo_comun']}\")\n",
        "    if pd.notna(row.get('aumentativo_comun')): details.append(f\"<b>Aumentativo:</b> {row['aumentativo_comun']}\")\n",
        "\n",
        "    # --- Otros Campos ---\n",
        "    if pd.notna(row.get('subtipo')) and row.get('categoria') in ['conjunción', 'interjección']:\n",
        "         details.append(f\"<b>Subtipo:</b> {row['subtipo']}\")\n",
        "    if pd.notna(row.get('emocion_tipica')): details.append(f\"<b>Emoción:</b> {row['emocion_tipica']}\")\n",
        "    if pd.notna(row.get('funcion')): details.append(f\"<b>Función:</b> {row['funcion']}\")\n",
        "    if pd.notna(row.get('descripcion')): details.append(f\"<b>Desc.:</b> {row['descripcion']}\")\n",
        "\n",
        "    # --- Definiciones (Opcional, pueden ser largas) ---\n",
        "    if pd.notna(row.get('definicion_contextual')): details.append(f\"<b>Def. Context.:</b> {textwrap.shorten(row['definicion_contextual'], width=80, placeholder='...')}\")\n",
        "    if pd.notna(row.get('definicion_general')): details.append(f\"<b>Def. Gral.:</b> {textwrap.shorten(row['definicion_general'], width=80, placeholder='...')}\")\n",
        "\n",
        "    # Unir los detalles con saltos de línea HTML\n",
        "    tooltip_html = \"<br>\".join(details)\n",
        "\n",
        "    return tooltip_html if details else \"<i>(Sin detalles adicionales)</i>\"\n",
        "\n",
        "# --- Inicio del Chunk 6 ---\n",
        "print(\"--- 6.1 Creando DataFrame Final 'df_plot_final' (con Tooltip Dinámico) ---\")\n",
        "\n",
        "df_plot_final = None\n",
        "\n",
        "# Verificar DataFrame combinado del paso anterior\n",
        "if 'df_embeddings_combinado' in globals() and isinstance(df_embeddings_combinado, pd.DataFrame) and not df_embeddings_combinado.empty:\n",
        "\n",
        "    # Verificar si las columnas de coordenadas esenciales existen\n",
        "    has_umap_coords = 'umap_x' in df_embeddings_combinado.columns and 'umap_y' in df_embeddings_combinado.columns and not df_embeddings_combinado['umap_x'].isnull().all()\n",
        "    has_pca_coords = 'pca_x' in df_embeddings_combinado.columns and 'pca_y' in df_embeddings_combinado.columns and not df_embeddings_combinado['pca_x'].isnull().all()\n",
        "\n",
        "    if has_umap_coords or has_pca_coords:\n",
        "        df_plot_final = df_embeddings_combinado.copy()\n",
        "        print(f\"-> Copiando df_embeddings_combinado ({len(df_plot_final)} filas) a df_plot_final.\")\n",
        "\n",
        "        # --- 6.2 Crear Columna de Tooltip Formateado ---\n",
        "        print(\"   -> Creando columna 'tooltip_details' formateada dinámicamente...\")\n",
        "        try:\n",
        "            df_plot_final['tooltip_details'] = df_plot_final.apply(format_tooltip_details, axis=1)\n",
        "            print(\"      -> Columna 'tooltip_details' creada exitosamente.\")\n",
        "        except Exception as e:\n",
        "            print(f\"   (!) Error al crear 'tooltip_details': {e}\")\n",
        "            df_plot_final['tooltip_details'] = \"Error al formatear\" # Fallback\n",
        "\n",
        "        # --- 6.3 Asegurar otras Columnas Necesarias ---\n",
        "        columnas_base_plot = ['texto', 'tipo', 'indice_ref', 'categoria', 'tooltip_details'] # Columnas descriptivas + tooltip\n",
        "        columnas_coords_plot = []\n",
        "        if has_umap_coords: columnas_coords_plot.extend(['umap_x', 'umap_y', 'umap_x_3d', 'umap_y_3d', 'umap_z_3d']) # Incluir 3D si existen\n",
        "        if has_pca_coords: columnas_coords_plot.extend(['pca_x', 'pca_y', 'pca_x_3d', 'pca_y_3d', 'pca_z_3d']) # Incluir 3D si existen\n",
        "\n",
        "        columnas_plot_final = columnas_base_plot + columnas_coords_plot\n",
        "\n",
        "        columnas_faltantes_plot = [col for col in columnas_plot_final if col not in df_plot_final.columns]\n",
        "        if not columnas_faltantes_plot:\n",
        "             print(\"   -> Todas las columnas necesarias para visualización están presentes o se manejarán.\")\n",
        "             if 'frase_seleccionada' in globals(): df_plot_final['frase_madre'] = frase_seleccionada\n",
        "             else: df_plot_final['frase_madre'] = 'Desconocida'\n",
        "             columnas_plot_final.append('frase_madre') # Añadir a la lista final\n",
        "\n",
        "             print(\"\\n-> DataFrame 'df_plot_final' listo.\")\n",
        "             # Mostrar cabecera con columnas clave, incluyendo el nuevo tooltip\n",
        "             print(\"\\n   Primeras filas de 'df_plot_final' (con tooltip_details):\")\n",
        "             cols_to_show = ['texto', 'tipo', 'categoria', 'tooltip_details'] + [c for c in columnas_coords_plot if c in df_plot_final.columns]\n",
        "             try:\n",
        "                 # Acortar tooltip para la vista previa del head\n",
        "                 df_head_preview = df_plot_final[cols_to_show].head().copy()\n",
        "                 if 'tooltip_details' in df_head_preview.columns:\n",
        "                      df_head_preview['tooltip_details'] = df_head_preview['tooltip_details'].apply(lambda x: textwrap.shorten(str(x).replace('<br>', ' | '), width=60, placeholder='...'))\n",
        "                 print(df_head_preview.to_markdown(index=False))\n",
        "             except ImportError: print(df_plot_final[cols_to_show].head())\n",
        "             except Exception as e: print(f\"(!) Error al mostrar head: {e}\"); print(df_plot_final.head())\n",
        "\n",
        "        else:\n",
        "             print(f\"(!) Advertencia: Faltan columnas base o de coordenadas: {columnas_faltantes_plot}\")\n",
        "             df_plot_final = df_plot_final[[col for col in columnas_plot_final if col in df_plot_final.columns]] # Mantener solo existentes\n",
        "\n",
        "    else:\n",
        "        print(\"(!) Error: Sin coordenadas 2D válidas en 'df_embeddings_combinado'.\")\n",
        "        df_plot_final = pd.DataFrame()\n",
        "else:\n",
        "    print(\"(!) Error: 'df_embeddings_combinado' no encontrado o vacío.\")\n",
        "    df_plot_final = pd.DataFrame()\n",
        "\n",
        "# --- Fin Chunk 6 (Revisado v3) ---\n",
        "print(\"\\n--- Fin del Proceso del Chunk 6 Revisado v3 ---\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S9beI9Ypeh5z",
        "outputId": "8c48a3d7-f79d-4018-c0cb-01fc36b2675f"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- 6.1 Creando DataFrame Final 'df_plot_final' (con Tooltip Dinámico) ---\n",
            "-> Copiando df_embeddings_combinado (57 filas) a df_plot_final.\n",
            "   -> Creando columna 'tooltip_details' formateada dinámicamente...\n",
            "      -> Columna 'tooltip_details' creada exitosamente.\n",
            "(!) Advertencia: Faltan columnas base o de coordenadas: ['umap_x_3d', 'umap_y_3d', 'umap_z_3d', 'pca_x_3d', 'pca_y_3d', 'pca_z_3d']\n",
            "\n",
            "--- Fin del Proceso del Chunk 6 Revisado v3 ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 7 (Revisado v2 - Mejorado): Visualización Jerárquica (Palabras y Unidades)\n",
        "\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "import pandas as pd\n",
        "import textwrap\n",
        "import numpy as np # Para verificar NaNs\n",
        "\n",
        "print(\"--- 7.1 Preparando Visualización Jerárquica ---\")\n",
        "\n",
        "# --- Parámetros de Visualización ---\n",
        "\n",
        "# @markdown ---\n",
        "# @markdown **Selección de Coordenadas:**\n",
        "# @markdown Elige qué método de reducción de dimensionalidad usar para el gráfico.\n",
        "# @markdown *   **UMAP:** Generalmente mejor para visualización. Tiende a preservar mejor la estructura local (grupos de puntos cercanos) y también da una buena idea de la estructura global. Bueno para exploración.\n",
        "# @markdown *   **PCA:** Más rápido de calcular. Preserva la varianza global (las direcciones de mayor dispersión). Útil si la estructura lineal de los datos es importante o como una alternativa si UMAP da resultados extraños.\n",
        "coords_a_usar = \"UMAP\" # @param [\"UMAP\", \"PCA\"]\n",
        "\n",
        "# @markdown ---\n",
        "# @markdown **Apariencia del Gráfico:**\n",
        "# @markdown Ajusta la opacidad de las líneas que conectan las palabras (0=invisible, 1=opaco):\n",
        "opacidad_linea = 0.25 # @param {type:\"slider\", min:0.0, max:1.0, step:0.05}\n",
        "# @markdown ¿Mostrar palabras directamente en los puntos? (Puede causar solapamiento)\n",
        "mostrar_texto_en_puntos = False # @param {type:\"boolean\"}\n",
        "# @markdown Tamaño de los puntos de las palabras:\n",
        "tamano_punto_palabra = 11 # @param {type:\"slider\", min:4, max:20, step:1}\n",
        "# @markdown ¿Mostrar marcadores para las Unidades/Texto Completo?\n",
        "mostrar_marcadores_unidad = True # @param {type:\"boolean\"}\n",
        "# @markdown Tamaño de los marcadores de Unidad/Texto Completo:\n",
        "tamano_punto_unidad = 23 # @param {type:\"slider\", min:8, max:24, step:1}\n",
        "# @markdown ---\n",
        "\n",
        "fig_combinada = None # Inicializar figura\n",
        "\n",
        "# Verificar DataFrame y columnas necesarias\n",
        "if 'df_embeddings_combinado' not in globals() or not isinstance(df_embeddings_combinado, pd.DataFrame) or df_embeddings_combinado.empty:\n",
        "    print(\"(!) Error: DataFrame 'df_embeddings_combinado' no encontrado o vacío.\")\n",
        "elif 'tipo' not in df_embeddings_combinado.columns or 'embedding_vector' not in df_embeddings_combinado.columns:\n",
        "     print(\"(!) Error: Faltan columnas 'tipo' o 'embedding_vector' en 'df_embeddings_combinado'.\")\n",
        "else:\n",
        "    # Determinar columnas X e Y y verificar su existencia\n",
        "    x_col = 'umap_x' if coords_a_usar == \"UMAP\" else 'pca_x'\n",
        "    y_col = 'umap_y' if coords_a_usar == \"UMAP\" else 'pca_y'\n",
        "    coord_label = coords_a_usar\n",
        "\n",
        "    if x_col not in df_embeddings_combinado.columns or y_col not in df_embeddings_combinado.columns:\n",
        "        print(f\"(!) Error: Columnas de coordenadas '{x_col}' o '{y_col}' no existen.\")\n",
        "    # Verificar que haya al menos algunos valores no nulos en las coordenadas seleccionadas\n",
        "    elif df_embeddings_combinado[x_col].isnull().all() or df_embeddings_combinado[y_col].isnull().all():\n",
        "         print(f\"(!) Advertencia: Coordenadas {coord_label} seleccionadas contienen solo NaN.\")\n",
        "         # No se puede graficar\n",
        "    else:\n",
        "        print(f\"-> Usando coordenadas {coord_label}. Opacidad línea: {opacidad_linea}. Mostrar texto: {mostrar_texto_en_puntos}.\")\n",
        "\n",
        "        # Filtrar filas donde las coordenadas seleccionadas son NaN (no se pueden graficar)\n",
        "        df_plot_valid = df_embeddings_combinado.dropna(subset=[x_col, y_col]).copy()\n",
        "        if len(df_plot_valid) < len(df_embeddings_combinado):\n",
        "             print(f\"(!) Advertencia: Se omitieron {len(df_embeddings_combinado) - len(df_plot_valid)} elementos con coordenadas NaN.\")\n",
        "\n",
        "        if df_plot_valid.empty:\n",
        "             print(\"(!) No quedan elementos válidos para graficar después de quitar NaN.\")\n",
        "        else:\n",
        "            # --- 7.3 Crear Gráfico Jerárquico ---\n",
        "            print(\"-> Creando gráfico jerárquico interactivo...\")\n",
        "            try:\n",
        "                fig_combinada = go.Figure()\n",
        "                colores_plotly = px.colors.qualitative.Plotly # Usar una paleta estándar\n",
        "\n",
        "                # Asegurar orden para las líneas: por índice de unidad, luego por índice de palabra\n",
        "                df_plot_valid['id_unidad_num'] = df_plot_valid.apply(lambda row: 0 if row['tipo']=='TextoCompleto' else (row['indice_ref'] if row['tipo']=='Unidad' else np.inf), axis=1)\n",
        "                df_plot_valid['indice_palabra_num'] = df_plot_valid.apply(lambda row: row['indice_ref'] if row['tipo']=='Palabra' else np.inf, axis=1)\n",
        "                df_plot_valid_sorted = df_plot_valid.sort_values(by=['id_unidad_num', 'indice_palabra_num']).reset_index()\n",
        "\n",
        "                # --- Capa 1: Líneas conectando palabras dentro de cada unidad ---\n",
        "                # Necesitamos agrupar por unidad. El texto completo es una unidad (índice 0).\n",
        "                # Las unidades detectadas tienen índice 1, 2, ...\n",
        "                # Si solo hay texto completo, su índice_ref es 0. Si hay unidades, van de 1 en adelante.\n",
        "                # Si hay palabras, su índice_ref es el índice de palabra. Necesitamos mapear palabras a unidades.\n",
        "\n",
        "                # Mapeo (aproximado): Asignar palabras a la unidad más cercana en el índice original\n",
        "                # Esta lógica asume que parsed_json (de donde vienen las palabras) y\n",
        "                # lista_unidades_detectadas (de donde vienen las unidades) están relacionadas con la estructura.\n",
        "                # Es una simplificación; un mapeo perfecto requeriría info del paso de segmentación.\n",
        "\n",
        "                # Heurística simple: Dibujar una línea continua entre todas las palabras si no hay unidades claras\n",
        "                palabras_df = df_plot_valid_sorted[df_plot_valid_sorted['tipo'] == 'Palabra']\n",
        "                if not palabras_df.empty:\n",
        "                    fig_combinada.add_trace(go.Scatter(\n",
        "                        x=palabras_df[x_col],\n",
        "                        y=palabras_df[y_col],\n",
        "                        mode='lines',\n",
        "                        line=dict(color=f'rgba(0,0,0,{opacidad_linea})', width=1.5), # Usar opacidad del @markdown\n",
        "                        hoverinfo='none',\n",
        "                        showlegend=False\n",
        "                    ))\n",
        "                    print(f\"   -> Añadida línea conectando {len(palabras_df)} palabras.\")\n",
        "\n",
        "\n",
        "                # --- Capa 2: Puntos de las Palabras ---\n",
        "                if not palabras_df.empty:\n",
        "                    # Usar px.scatter para generar trazas por categoría fácilmente\n",
        "                    scatter_palabras = px.scatter(\n",
        "                        palabras_df, x=x_col, y=y_col, color='categoria',\n",
        "                        hover_name='texto', # <--- CORREGIDO\n",
        "                        hover_data={'categoria': True, 'indice_ref': True, x_col: ':.3f', y_col: ':.3f'},\n",
        "                        text='texto' # <--- CORREGIDO (El texto se mostrará o no según el update_traces)\n",
        "                    )\n",
        "                    for trace in scatter_palabras.data:\n",
        "                        trace.update(marker_size=tamano_punto_palabra) # Aplicar tamaño\n",
        "                        fig_combinada.add_trace(trace)\n",
        "                    print(f\"   -> Añadidos {len(palabras_df)} puntos de palabras coloreados por categoría.\")\n",
        "\n",
        "\n",
        "                # --- Capa 3: Marcadores de Unidades y Texto Completo ---\n",
        "                if mostrar_marcadores_unidad:\n",
        "                    unidades_df = df_plot_valid_sorted[df_plot_valid_sorted['tipo'] == 'Unidad']\n",
        "                    texto_completo_df = df_plot_valid_sorted[df_plot_valid_sorted['tipo'] == 'TextoCompleto']\n",
        "\n",
        "                    if not unidades_df.empty:\n",
        "                        fig_combinada.add_trace(go.Scatter(\n",
        "                            x=unidades_df[x_col], y=unidades_df[y_col],\n",
        "                            mode='markers',\n",
        "                            marker=dict(symbol='star', size=tamano_punto_unidad, color='orange',\n",
        "                                        line=dict(width=1, color='DarkSlateGrey')),\n",
        "                            name='Unidad Detectada', # Nombre para la leyenda\n",
        "                            text=[f\"Unidad {idx}\" for idx in unidades_df['indice_ref']], # Texto para hover\n",
        "                            hoverinfo='text+x+y'\n",
        "                        ))\n",
        "                        print(f\"   -> Añadidos {len(unidades_df)} marcadores para Unidades.\")\n",
        "\n",
        "                    if not texto_completo_df.empty:\n",
        "                        fig_combinada.add_trace(go.Scatter(\n",
        "                            x=texto_completo_df[x_col], y=texto_completo_df[y_col],\n",
        "                            mode='markers',\n",
        "                            marker=dict(symbol='diamond', size=tamano_punto_unidad, color='green',\n",
        "                                        line=dict(width=1, color='DarkSlateGrey')),\n",
        "                            name='Texto Completo',\n",
        "                            text='Texto Completo',\n",
        "                            hoverinfo='text+x+y'\n",
        "                        ))\n",
        "                        print(f\"   -> Añadido marcador para Texto Completo.\")\n",
        "\n",
        "\n",
        "                # --- 7.4 Ajustar Diseño y Apariencia ---\n",
        "                # Ocultar/mostrar texto en puntos de palabras\n",
        "                fig_combinada.update_traces(\n",
        "                    text=None if not mostrar_texto_en_puntos else 'default', # 'default' usa el texto asignado\n",
        "                    textposition='top center',\n",
        "                    textfont_size=9,\n",
        "                    selector=dict(type='scatter', mode='markers') # Aplicar solo a trazas con marcadores\n",
        "                 )\n",
        "\n",
        "                # Layout General\n",
        "                titulo_grafico = f\"Mapa Semántico Jerárquico ({coord_label})\"\n",
        "                if 'frase_seleccionada' in globals():\n",
        "                     titulo_grafico += f\"<br>Texto: <i>{textwrap.shorten(frase_seleccionada, width=90)}</i>\"\n",
        "\n",
        "                fig_combinada.update_layout(\n",
        "                    title=titulo_grafico,\n",
        "                    hovermode='closest',\n",
        "                    xaxis=dict(showticklabels=False, showgrid=False, zeroline=False, title=None),\n",
        "                    yaxis=dict(showticklabels=False, showgrid=False, zeroline=False, title=None),\n",
        "                    legend_title_text='Tipo / Categoría',\n",
        "                    template='plotly_white',\n",
        "                    margin=dict(l=20, r=20, t=90, b=20) # Más margen para título\n",
        "                )\n",
        "\n",
        "                print(\"-> Gráfico jerárquico creado/actualizado.\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"(!) Error inesperado al crear el gráfico Plotly jerárquico: {e}\")\n",
        "                # import traceback\n",
        "                # traceback.print_exc() # Descomentar para ver el traceback completo si hay errores difíciles\n",
        "                fig_combinada = None\n",
        "\n",
        "# --- 7.5 Mostrar Contexto y Gráfico ---\n",
        "# (El código para mostrar Frase Original y Meta-CoT es el mismo que antes)\n",
        "# ... (código para imprimir contexto) ...\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"Contexto para la Visualización Jerárquica:\")\n",
        "print(\"=\"*70)\n",
        "if 'frase_seleccionada' in globals(): print(f\"Texto Original Seleccionado:\\n{textwrap.fill(frase_seleccionada, width=80)}\\n\")\n",
        "else: print(\"Texto Original no disponible.\")\n",
        "print(\"-\"*70)\n",
        "print(\"Meta-Análisis CoT (Resumen):\")\n",
        "print(\"-\"*70)\n",
        "if 'meta_cot_resumen' in globals() and meta_cot_resumen:\n",
        "    from IPython.display import display, Markdown; display(Markdown(meta_cot_resumen))\n",
        "else: print(\"(Meta-Análisis CoT no disponible)\")\n",
        "print(\"=\"*70 + \"\\n\")\n",
        "\n",
        "# Mostrar el gráfico\n",
        "if fig_combinada is not None:\n",
        "    print(\"\\n--- Mostrando Gráfico Interactivo Jerárquico ---\")\n",
        "    print(\"Puntos: Palabras (color=categoría), Estrellas: Unidades, Diamante: Texto Completo.\")\n",
        "    print(\"Líneas conectan palabras en secuencia.\")\n",
        "    print(\"(Pasa el ratón sobre los puntos para ver detalles)\")\n",
        "    fig_combinada.show()\n",
        "else:\n",
        "    print(\"\\n(!) El gráfico jerárquico no pudo ser generado o mostrado.\")\n",
        "\n",
        "\n",
        "# --- Fin Chunk 7 (Revisado v2 - Mejorado) ---\n",
        "print(\"\\n--- Fin del Proceso del Chunk 7 Revisado v2 y Mejorado ---\")"
      ],
      "metadata": {
        "id": "SHuEaOHde6vJ",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 9. Reducción de Dimensionalidad a 3D (UMAP y PCA)\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import umap\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "print(\"--- 9.1 Preparando embeddings COMBINADOS para reducción a 3D ---\")\n",
        "\n",
        "embeddings_3d_umap = None\n",
        "embeddings_3d_pca = None\n",
        "reduction_3d_successful = False\n",
        "\n",
        "# Verificar DataFrame combinado\n",
        "if 'df_embeddings_combinado' in globals() and isinstance(df_embeddings_combinado, pd.DataFrame) and not df_embeddings_combinado.empty \\\n",
        "   and 'embedding_vector' in df_embeddings_combinado.columns:\n",
        "\n",
        "    valid_embeddings_series_3d = df_embeddings_combinado['embedding_vector'].dropna()\n",
        "    if not valid_embeddings_series_3d.empty:\n",
        "        embedding_vectors_list_3d = valid_embeddings_series_3d.tolist()\n",
        "        try:\n",
        "            valid_vectors_3d = [vec for vec in embedding_vectors_list_3d if isinstance(vec, np.ndarray)]\n",
        "            if valid_vectors_3d:\n",
        "                embeddings_array_3d = np.stack(valid_vectors_3d, axis=0)\n",
        "                print(f\"-> Array de embeddings preparado para 3D. Forma: {embeddings_array_3d.shape}\")\n",
        "\n",
        "                # Necesitamos al menos 3 puntos para PCA 3D, y preferiblemente > n_neighbors para UMAP 3D\n",
        "                if embeddings_array_3d.shape[0] >= 3:\n",
        "                    reduction_3d_possible = True\n",
        "                else:\n",
        "                    print(\"(!) No hay suficientes puntos (se necesitan >= 3) para reducción a 3D significativa.\")\n",
        "                    reduction_3d_possible = False\n",
        "\n",
        "            else: reduction_3d_possible = False\n",
        "        except Exception as e:\n",
        "            print(f\"(!) Error al preparar array para 3D: {e}\"); reduction_3d_possible = False\n",
        "    else:\n",
        "        print(\"(!) No hay embeddings válidos en 'df_embeddings_combinado'.\"); reduction_3d_possible = False\n",
        "else:\n",
        "    print(\"(!) DataFrame 'df_embeddings_combinado' no encontrado o inválido.\"); reduction_3d_possible = False\n",
        "\n",
        "# --- 9.2 Aplicar Reducción a 3D (si es posible) ---\n",
        "if reduction_3d_possible:\n",
        "    print(\"\\n--- 9.2 Aplicando Reducción de Dimensionalidad a 3D ---\")\n",
        "\n",
        "    # --- UMAP 3D ---\n",
        "    print(\"   -> Calculando reducción 3D con UMAP...\")\n",
        "    try:\n",
        "        n_samples = embeddings_array_3d.shape[0]\n",
        "        # UMAP 3D puede necesitar más vecinos, pero mantenemos la heurística\n",
        "        n_neighbors_umap_3d = min(15, max(2, n_samples - 1)) if n_samples > 2 else 1\n",
        "        print(f\"      (Usando n_neighbors={n_neighbors_umap_3d})\")\n",
        "\n",
        "        umap_reducer_3d = umap.UMAP(\n",
        "            n_components=3, # <--- CAMBIO CLAVE\n",
        "            n_neighbors=n_neighbors_umap_3d, min_dist=0.1,\n",
        "            metric='cosine', random_state=42, n_jobs=1\n",
        "        )\n",
        "        embeddings_3d_umap = umap_reducer_3d.fit_transform(embeddings_array_3d)\n",
        "        print(f\"      -> Reducción UMAP 3D completada. Forma: {embeddings_3d_umap.shape}\")\n",
        "        reduction_3d_successful = True\n",
        "    except Exception as e:\n",
        "        print(f\"   (!) Error durante la reducción UMAP 3D: {e}\")\n",
        "        embeddings_3d_umap = None\n",
        "        if not reduction_3d_successful: print(\"      Intentando PCA 3D como alternativa...\")\n",
        "\n",
        "    # --- PCA 3D ---\n",
        "    print(\"\\n   -> Calculando reducción 3D con PCA...\")\n",
        "    try:\n",
        "        pca_reducer_3d = PCA(\n",
        "            n_components=3, # <--- CAMBIO CLAVE\n",
        "            random_state=42\n",
        "        )\n",
        "        embeddings_3d_pca = pca_reducer_3d.fit_transform(embeddings_array_3d)\n",
        "        print(f\"      -> Reducción PCA 3D completada. Forma: {embeddings_3d_pca.shape}\")\n",
        "        if not reduction_3d_successful: reduction_3d_successful = True\n",
        "    except Exception as e:\n",
        "        print(f\"   (!) Error durante la reducción PCA 3D: {e}\")\n",
        "        embeddings_3d_pca = None\n",
        "\n",
        "# --- 9.3 Añadir Coordenadas 3D al DataFrame Final ---\n",
        "# Usaremos el df_plot_final del Chunk 6 (que ya tiene otras infos)\n",
        "if 'df_plot_final' in globals() and isinstance(df_plot_final, pd.DataFrame) and not df_plot_final.empty:\n",
        "    if reduction_3d_successful:\n",
        "        print(\"\\n--- 9.3 Añadiendo coordenadas 3D al DataFrame 'df_plot_final' ---\")\n",
        "        # Asegurarse de alinear con los índices correctos (los que tenían embeddings válidos)\n",
        "        indices_validos_3d = valid_embeddings_series_3d.index\n",
        "\n",
        "        try:\n",
        "            # Añadir UMAP 3D\n",
        "            if embeddings_3d_umap is not None and embeddings_3d_umap.shape[0] == len(indices_validos_3d):\n",
        "                 df_coords_umap_3d = pd.DataFrame(embeddings_3d_umap, columns=['umap_x_3d', 'umap_y_3d', 'umap_z_3d'], index=indices_validos_3d)\n",
        "                 df_plot_final = df_plot_final.join(df_coords_umap_3d)\n",
        "                 print(\"   -> Coordenadas UMAP 3D añadidas.\")\n",
        "            else:\n",
        "                 print(\"   (!) No se añadieron coordenadas UMAP 3D.\")\n",
        "                 if 'umap_x_3d' not in df_plot_final.columns: df_plot_final['umap_x_3d'] = np.nan # Añadir NaN si no existen\n",
        "                 if 'umap_y_3d' not in df_plot_final.columns: df_plot_final['umap_y_3d'] = np.nan\n",
        "                 if 'umap_z_3d' not in df_plot_final.columns: df_plot_final['umap_z_3d'] = np.nan\n",
        "\n",
        "            # Añadir PCA 3D\n",
        "            if embeddings_3d_pca is not None and embeddings_3d_pca.shape[0] == len(indices_validos_3d):\n",
        "                 df_coords_pca_3d = pd.DataFrame(embeddings_3d_pca, columns=['pca_x_3d', 'pca_y_3d', 'pca_z_3d'], index=indices_validos_3d)\n",
        "                 df_plot_final = df_plot_final.join(df_coords_pca_3d)\n",
        "                 print(\"   -> Coordenadas PCA 3D añadidas.\")\n",
        "            else:\n",
        "                 print(\"   (!) No se añadieron coordenadas PCA 3D.\")\n",
        "                 if 'pca_x_3d' not in df_plot_final.columns: df_plot_final['pca_x_3d'] = np.nan\n",
        "                 if 'pca_y_3d' not in df_plot_final.columns: df_plot_final['pca_y_3d'] = np.nan\n",
        "                 if 'pca_z_3d' not in df_plot_final.columns: df_plot_final['pca_z_3d'] = np.nan\n",
        "\n",
        "        except Exception as e:\n",
        "              print(f\"(!) Error al añadir coordenadas 3D al DataFrame: {e}\")\n",
        "\n",
        "    else: # Si la reducción 3D no fue posible o falló\n",
        "        print(\"\\n--- 9.3 No se realizó o falló la reducción a 3D ---\")\n",
        "        # Añadir columnas NaN si no existen\n",
        "        for col in ['umap_x_3d', 'umap_y_3d', 'umap_z_3d', 'pca_x_3d', 'pca_y_3d', 'pca_z_3d']:\n",
        "             if col not in df_plot_final.columns: df_plot_final[col] = np.nan\n",
        "        print(\"   -> Columnas de coordenadas 3D añadidas como NaN.\")\n",
        "else:\n",
        "     print(\"(!) Error: No se encontró 'df_plot_final' para añadir coordenadas 3D.\")\n",
        "\n",
        "\n",
        "# --- Fin Chunk 9 ---\n",
        "print(\"\\n--- Fin del Proceso del Chunk 9 (Reducción 3D) ---\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "2FY7faoA03z2",
        "outputId": "89e9adbb-4bca-46ae-f899-aaf9d2eaa264"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- 9.1 Preparando embeddings COMBINADOS para reducción a 3D ---\n",
            "-> Array de embeddings preparado para 3D. Forma: (57, 768)\n",
            "\n",
            "--- 9.2 Aplicando Reducción de Dimensionalidad a 3D ---\n",
            "   -> Calculando reducción 3D con UMAP...\n",
            "      (Usando n_neighbors=15)\n",
            "      -> Reducción UMAP 3D completada. Forma: (57, 3)\n",
            "\n",
            "   -> Calculando reducción 3D con PCA...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
            "\n",
            "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      -> Reducción PCA 3D completada. Forma: (57, 3)\n",
            "\n",
            "--- 9.3 Añadiendo coordenadas 3D al DataFrame 'df_plot_final' ---\n",
            "   -> Coordenadas UMAP 3D añadidas.\n",
            "   -> Coordenadas PCA 3D añadidas.\n",
            "\n",
            "--- Fin del Proceso del Chunk 9 (Reducción 3D) ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 10 (v4 - Final): Visualización 3D con Tooltips Dinámicos\n",
        "\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "import pandas as pd\n",
        "import textwrap\n",
        "import numpy as np\n",
        "from IPython.display import display, Markdown # Para renderizar Markdown si muestras contexto aquí\n",
        "\n",
        "print(\"--- 10.1 Preparando Visualización 3D (v4 - Tooltips Dinámicos) ---\")\n",
        "\n",
        "# --- Parámetros de Visualización 3D ---\n",
        "# @markdown (Mismos parámetros @markdown que antes)\n",
        "# @markdown ---\n",
        "coords_3d_a_usar = \"UMAP\" # @param [\"UMAP\", \"PCA\"]\n",
        "# @markdown ---\n",
        "opacidad_linea_3d = 0.3 # @param {type:\"slider\", min:0.0, max:1.0, step:0.05}\n",
        "# ... (resto de parámetros) ...\n",
        "mostrar_texto_en_puntos = False # @param {type:\"boolean\"}\n",
        "tamano_punto_palabra_3d = 7 # @param {type:\"slider\", min:2, max:15, step:1}\n",
        "mostrar_marcadores_unidad_3d = True # @param {type:\"boolean\"}\n",
        "tamano_punto_unidad_3d = 10 # @param {type:\"slider\", min:4, max:20, step:1}\n",
        "# @markdown ---\n",
        "\n",
        "fig_3d = None\n",
        "\n",
        "# Verificar DataFrame y columnas\n",
        "# Verificar que df_plot_final y la columna tooltip_details existan\n",
        "if 'df_plot_final' not in globals() or not isinstance(df_plot_final, pd.DataFrame) or df_plot_final.empty:\n",
        "    print(\"(!) Error: DataFrame 'df_plot_final' no encontrado o vacío. Ejecuta Chunks 6 y 9.\")\n",
        "elif 'tooltip_details' not in df_plot_final.columns:\n",
        "     print(\"(!) Error: Falta la columna 'tooltip_details'. Ejecuta el Chunk 6 (Revisado v3) correctamente.\")\n",
        "# ... (resto de verificaciones iniciales de coordenadas 3D) ...\n",
        "else:\n",
        "    x_col_3d = f'{coords_3d_a_usar.lower()}_x_3d'\n",
        "    y_col_3d = f'{coords_3d_a_usar.lower()}_y_3d'\n",
        "    z_col_3d = f'{coords_3d_a_usar.lower()}_z_3d'\n",
        "    coord_label_3d = coords_3d_a_usar\n",
        "\n",
        "    # Verificar existencia y validez de coordenadas 3D\n",
        "    if not all(col in df_plot_final.columns for col in [x_col_3d, y_col_3d, z_col_3d]):\n",
        "        print(f\"(!) Error: Columnas 3D '{x_col_3d}', '{y_col_3d}', '{z_col_3d}' no existen. Ejecuta Chunk 9.\")\n",
        "    elif df_plot_final[[x_col_3d, y_col_3d, z_col_3d]].isnull().all().any():\n",
        "        print(f\"(!) Advertencia: Coordenadas 3D {coord_label_3d} con NaN.\")\n",
        "    else:\n",
        "        print(f\"-> Usando coordenadas 3D {coord_label_3d}.\")\n",
        "        # Usar .copy() para evitar warnings\n",
        "        df_plot_3d_valid = df_plot_final.dropna(subset=[x_col_3d, y_col_3d, z_col_3d]).copy()\n",
        "        # ... (código de advertencia si se omitieron NaNs) ...\n",
        "\n",
        "        if df_plot_3d_valid.empty:\n",
        "             print(\"(!) No quedan elementos válidos para graficar en 3D.\")\n",
        "        else:\n",
        "            print(\"-> Creando gráfico 3D interactivo (v4)...\")\n",
        "            try:\n",
        "                fig_3d = go.Figure()\n",
        "                # Reutilizar o regenerar mapa de colores\n",
        "                if 'color_map' not in globals() or not color_map:\n",
        "                    temp_palabras_df = df_plot_3d_valid[df_plot_3d_valid['tipo'] == 'Palabra']\n",
        "                    if not temp_palabras_df.empty:\n",
        "                        ordered_categories_3d = sorted(temp_palabras_df['categoria'].unique())\n",
        "                        color_sequence_3d = px.colors.qualitative.Plotly\n",
        "                        color_map = {cat: color_sequence_3d[i % len(color_sequence_3d)] for i, cat in enumerate(ordered_categories_3d)}\n",
        "                        print(\"   -> Mapa de colores regenerado para 3D.\")\n",
        "                    else: color_map = {}\n",
        "                else:\n",
        "                    color_map_3d = color_map\n",
        "                    print(\"   -> Usando mapa de colores existente.\")\n",
        "\n",
        "                # Ordenar para líneas\n",
        "                df_plot_3d_valid_sorted = df_plot_3d_valid.sort_values(by='indice_ref').reset_index(drop=True)\n",
        "                palabras_df_3d = df_plot_3d_valid_sorted[df_plot_3d_valid_sorted['tipo'] == 'Palabra']\n",
        "\n",
        "                # --- Capa 1: Líneas 3D conectando palabras ---\n",
        "                # ... (código sin cambios) ...\n",
        "                if not palabras_df_3d.empty:\n",
        "                    fig_3d.add_trace(go.Scatter3d(x=palabras_df_3d[x_col_3d], y=palabras_df_3d[y_col_3d], z=palabras_df_3d[z_col_3d],\n",
        "                                                  mode='lines', line=dict(color=f'rgba(0,0,0,{opacidad_linea_3d})', width=2),\n",
        "                                                  hoverinfo='none', showlegend=False))\n",
        "                    print(f\"   -> Añadida línea 3D conectando {len(palabras_df_3d)} palabras.\")\n",
        "\n",
        "\n",
        "                # --- Capa 2: Puntos 3D de las Palabras (Usando Tooltip Dinámico) --- ## ACTUALIZADO ##\n",
        "                if not palabras_df_3d.empty and color_map_3d:\n",
        "                    print(f\"   -> Añadiendo puntos 3D para palabras...\")\n",
        "                    for categoria, color in color_map_3d.items():\n",
        "                        df_categoria_3d = palabras_df_3d[palabras_df_3d['categoria'] == categoria]\n",
        "                        if not df_categoria_3d.empty:\n",
        "                             # Asegurarse que las columnas para customdata existen\n",
        "                             cols_custom_data = ['texto', 'tooltip_details', 'indice_ref']\n",
        "                             if all(c in df_categoria_3d.columns for c in cols_custom_data):\n",
        "                                 fig_3d.add_trace(go.Scatter3d(\n",
        "                                     x=df_categoria_3d[x_col_3d], y=df_categoria_3d[y_col_3d], z=df_categoria_3d[z_col_3d],\n",
        "                                     mode='markers',\n",
        "                                     marker=dict(color=color, size=tamano_punto_palabra_3d, opacity=0.9,\n",
        "                                                 line=dict(width=0.5, color='DarkSlateGrey')),\n",
        "                                     name=categoria,\n",
        "                                     customdata=df_categoria_3d[cols_custom_data], # Pasar las 3 columnas\n",
        "                                     hovertemplate=( # Usar el hovertemplate corregido\n",
        "                                         \"<b><u>%{customdata[0]}</u></b><br>\" # Palabra subrayada/negrita (índice 0)\n",
        "                                         f\"<b>Categoría:</b> {categoria} | <b>Índice:</b> %{{customdata[2]}}<br>\" # Cat (fija) e Índice (índice 2)\n",
        "                                         \"<br>\" # Separador\n",
        "                                         \"%{customdata[1]}\" # Detalles formateados (índice 1)\n",
        "                                         \"<br><br>\" # Separador antes de coords\n",
        "                                         f\"X: %{{x:.3f}}<br>\" # Coordenadas\n",
        "                                         f\"Y: %{{y:.3f}}<br>\"\n",
        "                                         f\"Z: %{{z:.3f}}\"\n",
        "                                         \"<extra></extra>\"\n",
        "                                     )\n",
        "                                 ))\n",
        "                             else:\n",
        "                                 print(f\"(!) Advertencia: Faltan columnas en customdata para categoría '{categoria}'. Se omite tooltip detallado.\")\n",
        "                                 # Añadir traza con tooltip básico si faltan datos\n",
        "                                 fig_3d.add_trace(go.Scatter3d(x=df_categoria_3d[x_col_3d], y=df_categoria_3d[y_col_3d], z=df_categoria_3d[z_col_3d],\n",
        "                                                              mode='markers', marker=dict(color=color, size=tamano_punto_palabra_3d), name=categoria,\n",
        "                                                              hovertext=df_categoria_3d['texto'])) # Tooltip básico con el texto\n",
        "\n",
        "                    print(f\"      -> Puntos 3D añadidos para {len(color_map_3d)} categorías con tooltips dinámicos.\")\n",
        "                # ... (código fallback sin cambios) ...\n",
        "\n",
        "                # --- Capa 3: Marcadores 3D Unidades / Texto Completo (Usando Tooltip Dinámico) --- ## ACTUALIZADO ##\n",
        "                if mostrar_marcadores_unidad_3d:\n",
        "                    unidades_df_3d = df_plot_3d_valid_sorted[df_plot_3d_valid_sorted['tipo'] == 'Unidad'].copy() # Usar copia\n",
        "                    texto_completo_df_3d = df_plot_3d_valid_sorted[df_plot_3d_valid_sorted['tipo'] == 'TextoCompleto'].copy() # Usar copia\n",
        "                    primera_palabra_3d = palabras_df_3d.iloc[0] if not palabras_df_3d.empty else None\n",
        "\n",
        "                    # Marcador Texto Completo\n",
        "                    if not texto_completo_df_3d.empty:\n",
        "                        tc_row_3d = texto_completo_df_3d.iloc[0]\n",
        "                        # Usar tooltip_details directamente si existe\n",
        "                        tooltip_tc = tc_row_3d.get('tooltip_details', \"Info no disponible\")\n",
        "                        fig_3d.add_trace(go.Scatter3d(\n",
        "                            x=[tc_row_3d[x_col_3d]], y=[tc_row_3d[y_col_3d]], z=[tc_row_3d[z_col_3d]], mode='markers',\n",
        "                            marker=dict(symbol='diamond', size=tamano_punto_unidad_3d, color='green', line_width=1, line_color='DarkSlateGrey'),\n",
        "                            name='Texto Completo',\n",
        "                            customdata=[[tooltip_tc]], # Pasar detalles formateados\n",
        "                            hovertemplate=\"%{customdata[0]}<extra></extra>\" # Mostrar detalles directamente\n",
        "                        ))\n",
        "                        print(f\"   -> Añadido marcador 3D Texto Completo (diamond).\")\n",
        "                        # ... (código línea punteada sin cambios) ...\n",
        "                        if primera_palabra_3d is not None:\n",
        "                             fig_3d.add_trace(go.Scatter3d(x=[tc_row_3d[x_col_3d], primera_palabra_3d[x_col_3d]], y=[tc_row_3d[y_col_3d], primera_palabra_3d[y_col_3d]], z=[tc_row_3d[z_col_3d], primera_palabra_3d[z_col_3d]], mode='lines', line=dict(color='rgba(0,128,0,0.5)', width=1.5, dash='dot'), hoverinfo='none', showlegend=False)); print(f\"      -> Añadida línea 3D conexión a 1ra palabra.\")\n",
        "\n",
        "\n",
        "                    # Marcadores Unidades Detectadas\n",
        "                    if not unidades_df_3d.empty:\n",
        "                         # Asegurar que tooltip_details existe\n",
        "                         if 'tooltip_details' not in unidades_df_3d.columns: unidades_df_3d['tooltip_details'] = \"Info no disponible\"\n",
        "                         # Añadir indice_ref a customdata si no está ya implícito\n",
        "                         if 'indice_ref' not in unidades_df_3d.columns: unidades_df_3d['indice_ref'] = 'N/A' # Fallback\n",
        "\n",
        "                         fig_3d.add_trace(go.Scatter3d(\n",
        "                             x=unidades_df_3d[x_col_3d], y=unidades_df_3d[y_col_3d], z=unidades_df_3d[z_col_3d], mode='markers',\n",
        "                             marker=dict(symbol='cross', size=tamano_punto_unidad_3d, color='orange', line_width=1),\n",
        "                             name='Unidad Detectada',\n",
        "                             # Pasar tooltip_details y el indice_ref\n",
        "                             customdata=unidades_df_3d[['tooltip_details', 'indice_ref']],\n",
        "                             hovertemplate=(\n",
        "                                 \"<b>Unidad Detectada #%{customdata[1]}</b><br>\" # Índice/número de unidad\n",
        "                                 \"<br>\" # Separador\n",
        "                                 \"%{customdata[0]}\" # Mostrar detalles base formateados\n",
        "                                 \"<extra></extra>\"\n",
        "                             )\n",
        "                         ))\n",
        "                         print(f\"   -> Añadidos {len(unidades_df_3d)} marcadores 3D Unidades (cross).\")\n",
        "\n",
        "\n",
        "                # --- 10.4 Ajustar Layout 3D y Texto ---\n",
        "                # ... (Código sin cambios significativos, asegurar selectores correctos) ...\n",
        "                fig_3d.update_traces(text=df_plot_3d_valid_sorted['texto'] if mostrar_texto_en_puntos else None, textposition='top center', textfont_size=9, selector=dict(type='scatter3d', mode='markers'))\n",
        "                if not mostrar_texto_en_puntos: fig_3d.update_traces(text=None, selector=dict(type='scatter3d', mode='markers'))\n",
        "                # ... (resto del layout) ...\n",
        "                titulo_grafico_3d = f\"Mapa Semántico 3D ({coord_label_3d})\" #...\n",
        "                if 'frase_seleccionada' in globals(): titulo_grafico_3d += f\"<br>Texto: <i>{textwrap.shorten(frase_seleccionada, width=120)}</i>\" #...\n",
        "                fig_3d.update_layout(title=titulo_grafico_3d, margin=dict(l=10, r=10, t=90, b=10), scene=dict(xaxis_title=f'{coord_label_3d} X', yaxis_title=f'{coord_label_3d} Y', zaxis_title=f'{coord_label_3d} Z', xaxis=dict(showticklabels=False, backgroundcolor=\"rgba(0,0,0,0)\", gridcolor=\"lightgrey\"), yaxis=dict(showticklabels=False, backgroundcolor=\"rgba(0,0,0,0)\", gridcolor=\"lightgrey\"), zaxis=dict(showticklabels=False, backgroundcolor=\"rgba(0,0,0,0)\", gridcolor=\"lightgrey\"), aspectratio=dict(x=1, y=1, z=0.7)), legend_title_text='Tipo / Categoría', template='plotly_white')\n",
        "\n",
        "\n",
        "                print(\"-> Gráfico 3D (v4) creado/actualizado.\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"(!) Error inesperado al crear el gráfico Plotly 3D v4: {e}\")\n",
        "                import traceback\n",
        "                traceback.print_exc()\n",
        "                fig_3d = None\n",
        "\n",
        "# --- 10.5 Mostrar Contexto y Gráfico 3D ---\n",
        "# ... (Código para mostrar contexto sin cambios) ...\n",
        "print(\"\\n\" + \"=\"*70); print(\"Contexto para la Visualización 3D:\"); print(\"=\"*70) #... (resto de impresión de contexto) ...\n",
        "if 'frase_seleccionada' in globals(): print(f\"Texto Original Seleccionado:\\n{textwrap.fill(frase_seleccionada, width=80)}\\n\") #...\n",
        "else: print(\"Texto Original no disponible.\") #...\n",
        "print(\"-\"*70); print(\"Meta-Análisis CoT (Resumen):\"); print(\"-\"*70) #...\n",
        "if 'meta_cot_resumen' in globals() and meta_cot_resumen: display(Markdown(meta_cot_resumen)) #...\n",
        "else: print(\"(Meta-Análisis CoT no disponible)\") #...\n",
        "print(\"=\"*70 + \"\\n\") #...\n",
        "\n",
        "# Mostrar el gráfico 3D\n",
        "if fig_3d is not None:\n",
        "    print(\"\\n--- Mostrando Gráfico Interactivo 3D (v4 - Tooltips Dinámicos) ---\")\n",
        "    fig_3d.show()\n",
        "else:\n",
        "    print(\"\\n(!) El gráfico 3D v4 no pudo ser generado o mostrado.\")\n",
        "\n",
        "# --- Fin Chunk 10 (v4) ---\n",
        "print(\"\\n--- Fin del Proceso del Chunk 10 (v4 - Tooltips Dinámicos) ---\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "rJ3ArI5t1EP-",
        "outputId": "c957b32b-4fa3-4af2-ee8e-2fe127085129"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- 10.1 Preparando Visualización 3D (v4 - Tooltips Dinámicos) ---\n",
            "-> Usando coordenadas 3D UMAP.\n",
            "-> Creando gráfico 3D interactivo (v4)...\n",
            "   -> Usando mapa de colores existente.\n",
            "   -> Añadida línea 3D conectando 54 palabras.\n",
            "   -> Añadiendo puntos 3D para palabras...\n",
            "      -> Puntos 3D añadidos para 7 categorías con tooltips dinámicos.\n",
            "   -> Añadido marcador 3D Texto Completo (diamond).\n",
            "      -> Añadida línea 3D conexión a 1ra palabra.\n",
            "   -> Añadidos 2 marcadores 3D Unidades (cross).\n",
            "-> Gráfico 3D (v4) creado/actualizado.\n",
            "\n",
            "======================================================================\n",
            "Contexto para la Visualización 3D:\n",
            "======================================================================\n",
            "Texto Original Seleccionado:\n",
            "Para realizar la configuración óptima del dispositivo, asegúrese de verificar\n",
            "que los puertos de entrada, los cuales suelen ubicarse en la parte posterior\n",
            "según el modelo adquirido, estén correctamente alineados con los conectores del\n",
            "cable HDMI, evitando así posibles fallos de transmisión de datos durante el\n",
            "proceso de sincronización.\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "Meta-Análisis CoT (Resumen):\n",
            "----------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "* Naturaleza: Instrucción técnica formal para la configuración de un dispositivo electrónico.  El texto pertenece a un manual de usuario o guía de configuración, con el objetivo de guiar al usuario en la conexión correcta del dispositivo.\n* Ambigüedad: Ausencia de ambigüedad significativa. El significado es claro y conciso, dirigido a evitar problemas de conexión.\n* Complejidad:  Estructura gramatical compleja, con una oración principal y una subordinada (que a su vez contiene una oración relativa).  Sin embargo, la complejidad gramatical no afecta la claridad del mensaje.  El texto utiliza vocabulario técnico específico del ámbito de la electrónica.\n* Conclusión Semántica: El texto cumple eficazmente su función instructiva, proporcionando instrucciones precisas y concisas para evitar fallos en la conexión del dispositivo.\n\n\n* Palabras unidas en sentido figurado: No hay palabras o frases unidas en sentido figurado. El lenguaje es completamente literal y técnico.  No presenta características literarias, poéticas o musicales."
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "\n",
            "\n",
            "--- Mostrando Gráfico Interactivo 3D (v4 - Tooltips Dinámicos) ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-3.0.1.min.js\"></script>                <div id=\"79a00500-9ba6-4579-a119-51b3da4d4712\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                window.PLOTLYENV=window.PLOTLYENV || {};                                if (document.getElementById(\"79a00500-9ba6-4579-a119-51b3da4d4712\")) {                    Plotly.newPlot(                        \"79a00500-9ba6-4579-a119-51b3da4d4712\",                        [{\"hoverinfo\":\"none\",\"line\":{\"color\":\"rgba(0,0,0,0.3)\",\"width\":2},\"mode\":\"lines\",\"showlegend\":false,\"x\":{\"dtype\":\"f4\",\"bdata\":\"dgbdQBrpwkCG0IVAxqbPQOxQwkCuJ\\u002fRAeGnaQClb0UArlt1AB8f5QGObzEA1QdJAVmiQQBpevEArmu5A0un0QOkH3kDOmo9Ak0zJQIbm70A9I9tAEJT2QEk8hUCASOFACeTHQHtp6ECAKvNAZ3TTQBrE5kAAD9FAM9n0QOwnvECJiuJAlvfjQIWMjUArPd5A3xD6QHFpzUBYJ85Aq7HAQCKF40B3xNZArkPAQCLgn0A9Af1AXtXRQJRM9UATn6dAv4vsQNkS+UAS58xA8V\\u002f0QMjlxEDZlsZA\"},\"y\":{\"dtype\":\"f4\",\"bdata\":\"oCc0QQ2uP0E6kktBjbJMQd6qPkEf9ShBxHpQQfqyN0HALS1BSD8sQQf0QUFyojJBqmJKQeCwQkGFdS1BVTo7QXiKN0EqzkxBcnI6QQBHLEEcnTdBCsoyQQVRSEGknzdB4AkzQV88KkE8CCJB5VxNQcKdSkGfITRBVBAuQf3gRkEaZklBR5cxQd8GS0HIoEdBv5QmQUkRMEG4izVBJj4zQb6FQUHT1CxBfIRDQaa1SUEjfy5BneBSQaS1KEG\\u002fNUdBkhdAQdkkJEEVg1BBI6YxQWaiT0GorjNB\"},\"z\":{\"dtype\":\"f4\",\"bdata\":\"rdc+QLz8pEDx7FtATXGpQEcGl0A0p+k\\u002fLMGfQMmFqUAzaJdAnM7CP8IIqkCE4lJA1yJUQC+lakD9vNY\\u002faaOHQM+iq0AEm1JADEBsQPcWeECul5lAU+eEQLwIS0CgeGxAp4WZQAjdi0BNzRBAfMWMQCLQm0AvTKNADZmEQHqcpUD62Y5AGdwVQMqaTUB2aoRAnNf6PxArtUCfZrpAtfmmQAZZn0BcD59AqsOLQEnYT0DgGOw\\u002fPs+uQJY+vj\\u002fNglhAlcl7QFxrHEAINYlAzpPSP0q2skCJfJBA\"},\"type\":\"scatter3d\"},{\"customdata\":[[\"óptima\",\"\\u003cb\\u003eLema:\\u003c\\u002fb\\u003e óptimo\\u003cbr\\u003e\\u003cb\\u003eGénero:\\u003c\\u002fb\\u003e femenino\\u003cbr\\u003e\\u003cb\\u003eNúmero:\\u003c\\u002fb\\u003e singular\\u003cbr\\u003e\\u003cb\\u003eTipo Espec.:\\u003c\\u002fb\\u003e Palabra\\u003cbr\\u003e\\u003cb\\u003eGrado:\\u003c\\u002fb\\u003e positiva\\u003cbr\\u003e\\u003cb\\u003eDef. Gral.:\\u003c\\u002fb\\u003e Que es la mejor o más adecuada.\",4],[\"posterior\",\"\\u003cb\\u003eLema:\\u003c\\u002fb\\u003e posterior\\u003cbr\\u003e\\u003cb\\u003eGénero:\\u003c\\u002fb\\u003e femenino\\u003cbr\\u003e\\u003cb\\u003eNúmero:\\u003c\\u002fb\\u003e singular\\u003cbr\\u003e\\u003cb\\u003eTipo Espec.:\\u003c\\u002fb\\u003e Palabra\\u003cbr\\u003e\\u003cb\\u003eGrado:\\u003c\\u002fb\\u003e positiva\\u003cbr\\u003e\\u003cb\\u003eDef. Gral.:\\u003c\\u002fb\\u003e Que está situado detrás o después.\",24],[\"adquirido\",\"\\u003cb\\u003eLema:\\u003c\\u002fb\\u003e adquirir\\u003cbr\\u003e\\u003cb\\u003eGénero:\\u003c\\u002fb\\u003e masculino\\u003cbr\\u003e\\u003cb\\u003eNúmero:\\u003c\\u002fb\\u003e singular\\u003cbr\\u003e\\u003cb\\u003eTipo Espec.:\\u003c\\u002fb\\u003e Palabra\\u003cbr\\u003e\\u003cb\\u003eDef. Gral.:\\u003c\\u002fb\\u003e Que se ha obtenido o comprado.\",28],[\"alineados\",\"\\u003cb\\u003eLema:\\u003c\\u002fb\\u003e alinear\\u003cbr\\u003e\\u003cb\\u003eGénero:\\u003c\\u002fb\\u003e masculino\\u003cbr\\u003e\\u003cb\\u003eNúmero:\\u003c\\u002fb\\u003e plural\\u003cbr\\u003e\\u003cb\\u003eTipo Espec.:\\u003c\\u002fb\\u003e Palabra\\u003cbr\\u003e\\u003cb\\u003eDef. Gral.:\\u003c\\u002fb\\u003e Que están en línea recta o en la misma dirección.\",32],[\"posibles\",\"\\u003cb\\u003eLema:\\u003c\\u002fb\\u003e posible\\u003cbr\\u003e\\u003cb\\u003eGénero:\\u003c\\u002fb\\u003e masculino\\u003cbr\\u003e\\u003cb\\u003eNúmero:\\u003c\\u002fb\\u003e plural\\u003cbr\\u003e\\u003cb\\u003eTipo Espec.:\\u003c\\u002fb\\u003e Palabra\\u003cbr\\u003e\\u003cb\\u003eGrado:\\u003c\\u002fb\\u003e positivo\\u003cbr\\u003e\\u003cb\\u003eDef. Gral.:\\u003c\\u002fb\\u003e Que puede ocurrir o hacerse.\",42]],\"hovertemplate\":\"\\u003cb\\u003e\\u003cu\\u003e%{customdata[0]}\\u003c\\u002fu\\u003e\\u003c\\u002fb\\u003e\\u003cbr\\u003e\\u003cb\\u003eCategoría:\\u003c\\u002fb\\u003e adjetivo | \\u003cb\\u003eÍndice:\\u003c\\u002fb\\u003e %{customdata[2]}\\u003cbr\\u003e\\u003cbr\\u003e%{customdata[1]}\\u003cbr\\u003e\\u003cbr\\u003eX: %{x:.3f}\\u003cbr\\u003eY: %{y:.3f}\\u003cbr\\u003eZ: %{z:.3f}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"marker\":{\"color\":\"#636EFA\",\"line\":{\"color\":\"DarkSlateGrey\",\"width\":0.5},\"opacity\":0.9,\"size\":7},\"mode\":\"markers\",\"name\":\"adjetivo\",\"x\":{\"dtype\":\"f4\",\"bdata\":\"7FDCQAnkx0AaxOZAiYriQK5DwEA=\"},\"y\":{\"dtype\":\"f4\",\"bdata\":\"3qo+QeAJM0HCnUpBGmZJQXyEQ0E=\"},\"z\":{\"dtype\":\"f4\",\"bdata\":\"RwaXQKeFmUAi0JtA+tmOQKrDi0A=\"},\"type\":\"scatter3d\",\"textfont\":{\"size\":9},\"textposition\":\"top center\"},{\"customdata\":[[\"que\",\"\\u003cb\\u003eTipo Espec.:\\u003c\\u002fb\\u003e Palabra\\u003cbr\\u003e\\u003cb\\u003eSubtipo:\\u003c\\u002fb\\u003e conjunción completiva\",11]],\"hovertemplate\":\"\\u003cb\\u003e\\u003cu\\u003e%{customdata[0]}\\u003c\\u002fu\\u003e\\u003c\\u002fb\\u003e\\u003cbr\\u003e\\u003cb\\u003eCategoría:\\u003c\\u002fb\\u003e conjunción | \\u003cb\\u003eÍndice:\\u003c\\u002fb\\u003e %{customdata[2]}\\u003cbr\\u003e\\u003cbr\\u003e%{customdata[1]}\\u003cbr\\u003e\\u003cbr\\u003eX: %{x:.3f}\\u003cbr\\u003eY: %{y:.3f}\\u003cbr\\u003eZ: %{z:.3f}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"marker\":{\"color\":\"#EF553B\",\"line\":{\"color\":\"DarkSlateGrey\",\"width\":0.5},\"opacity\":0.9,\"size\":7},\"mode\":\"markers\",\"name\":\"conjunción\",\"x\":{\"dtype\":\"f4\",\"bdata\":\"NUHSQA==\"},\"y\":{\"dtype\":\"f4\",\"bdata\":\"cqIyQQ==\"},\"z\":{\"dtype\":\"f4\",\"bdata\":\"hOJSQA==\"},\"type\":\"scatter3d\",\"textfont\":{\"size\":9},\"textposition\":\"top center\"},{\"customdata\":[[\"la\",\"\\u003cb\\u003eGénero:\\u003c\\u002fb\\u003e femenino\\u003cbr\\u003e\\u003cb\\u003eNúmero:\\u003c\\u002fb\\u003e singular\\u003cbr\\u003e\\u003cb\\u003eTipo Espec.:\\u003c\\u002fb\\u003e Palabra\\u003cbr\\u003e\\u003cb\\u003eSubtipo:\\u003c\\u002fb\\u003e determinado\",2],[\"los\",\"\\u003cb\\u003eGénero:\\u003c\\u002fb\\u003e masculino\\u003cbr\\u003e\\u003cb\\u003eNúmero:\\u003c\\u002fb\\u003e plural\\u003cbr\\u003e\\u003cb\\u003eTipo Espec.:\\u003c\\u002fb\\u003e Palabra\\u003cbr\\u003e\\u003cb\\u003eSubtipo:\\u003c\\u002fb\\u003e determinado\",12],[\"los\",\"\\u003cb\\u003eGénero:\\u003c\\u002fb\\u003e masculino\\u003cbr\\u003e\\u003cb\\u003eNúmero:\\u003c\\u002fb\\u003e plural\\u003cbr\\u003e\\u003cb\\u003eTipo Espec.:\\u003c\\u002fb\\u003e Palabra\\u003cbr\\u003e\\u003cb\\u003eSubtipo:\\u003c\\u002fb\\u003e determinado\",17],[\"la\",\"\\u003cb\\u003eGénero:\\u003c\\u002fb\\u003e femenino\\u003cbr\\u003e\\u003cb\\u003eNúmero:\\u003c\\u002fb\\u003e singular\\u003cbr\\u003e\\u003cb\\u003eTipo Espec.:\\u003c\\u002fb\\u003e Palabra\\u003cbr\\u003e\\u003cb\\u003eSubtipo:\\u003c\\u002fb\\u003e determinado\",22],[\"el\",\"\\u003cb\\u003eGénero:\\u003c\\u002fb\\u003e masculino\\u003cbr\\u003e\\u003cb\\u003eNúmero:\\u003c\\u002fb\\u003e singular\\u003cbr\\u003e\\u003cb\\u003eTipo Espec.:\\u003c\\u002fb\\u003e Palabra\\u003cbr\\u003e\\u003cb\\u003eSubtipo:\\u003c\\u002fb\\u003e determinado\",26],[\"los\",\"\\u003cb\\u003eGénero:\\u003c\\u002fb\\u003e masculino\\u003cbr\\u003e\\u003cb\\u003eNúmero:\\u003c\\u002fb\\u003e plural\\u003cbr\\u003e\\u003cb\\u003eTipo Espec.:\\u003c\\u002fb\\u003e Palabra\\u003cbr\\u003e\\u003cb\\u003eSubtipo:\\u003c\\u002fb\\u003e determinado\",34],[\"el\",\"\\u003cb\\u003eGénero:\\u003c\\u002fb\\u003e masculino\\u003cbr\\u003e\\u003cb\\u003eNúmero:\\u003c\\u002fb\\u003e singular\\u003cbr\\u003e\\u003cb\\u003eTipo Espec.:\\u003c\\u002fb\\u003e Palabra\\u003cbr\\u003e\\u003cb\\u003eSubtipo:\\u003c\\u002fb\\u003e determinado\",49]],\"hovertemplate\":\"\\u003cb\\u003e\\u003cu\\u003e%{customdata[0]}\\u003c\\u002fu\\u003e\\u003c\\u002fb\\u003e\\u003cbr\\u003e\\u003cb\\u003eCategoría:\\u003c\\u002fb\\u003e determinante | \\u003cb\\u003eÍndice:\\u003c\\u002fb\\u003e %{customdata[2]}\\u003cbr\\u003e\\u003cbr\\u003e%{customdata[1]}\\u003cbr\\u003e\\u003cbr\\u003eX: %{x:.3f}\\u003cbr\\u003eY: %{y:.3f}\\u003cbr\\u003eZ: %{z:.3f}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"marker\":{\"color\":\"#00CC96\",\"line\":{\"color\":\"DarkSlateGrey\",\"width\":0.5},\"opacity\":0.9,\"size\":7},\"mode\":\"markers\",\"name\":\"determinante\",\"x\":{\"dtype\":\"f4\",\"bdata\":\"htCFQFZokEDOmo9ASTyFQIAq80CFjI1A2RL5QA==\"},\"y\":{\"dtype\":\"f4\",\"bdata\":\"OpJLQapiSkEqzkxBBVFIQTwIIkHfBktB2SQkQQ==\"},\"z\":{\"dtype\":\"f4\",\"bdata\":\"8exbQNciVEAEm1JAvAhLQE3NEEDKmk1AXGscQA==\"},\"type\":\"scatter3d\",\"textfont\":{\"size\":9},\"textposition\":\"top center\"},{\"customdata\":[[\"Para\",\"\\u003cb\\u003eTipo Espec.:\\u003c\\u002fb\\u003e Palabra\",0],[\"del\",\"\\u003cb\\u003eTipo Espec.:\\u003c\\u002fb\\u003e Palabra\",5],[\"de\",\"\\u003cb\\u003eTipo Espec.:\\u003c\\u002fb\\u003e Palabra\",9],[\"de\",\"\\u003cb\\u003eTipo Espec.:\\u003c\\u002fb\\u003e Palabra\",14],[\"en\",\"\\u003cb\\u003eTipo Espec.:\\u003c\\u002fb\\u003e Palabra\",21],[\"según\",\"\\u003cb\\u003eTipo Espec.:\\u003c\\u002fb\\u003e Palabra\",25],[\"con\",\"\\u003cb\\u003eTipo Espec.:\\u003c\\u002fb\\u003e Palabra\",33],[\"del\",\"\\u003cb\\u003eTipo Espec.:\\u003c\\u002fb\\u003e Palabra\",36],[\"de\",\"\\u003cb\\u003eTipo Espec.:\\u003c\\u002fb\\u003e Palabra\",44],[\"de\",\"\\u003cb\\u003eTipo Espec.:\\u003c\\u002fb\\u003e Palabra\",46],[\"durante\",\"\\u003cb\\u003eTipo Espec.:\\u003c\\u002fb\\u003e Palabra\",48],[\"de\",\"\\u003cb\\u003eTipo Espec.:\\u003c\\u002fb\\u003e Palabra\",51]],\"hovertemplate\":\"\\u003cb\\u003e\\u003cu\\u003e%{customdata[0]}\\u003c\\u002fu\\u003e\\u003c\\u002fb\\u003e\\u003cbr\\u003e\\u003cb\\u003eCategoría:\\u003c\\u002fb\\u003e preposición | \\u003cb\\u003eÍndice:\\u003c\\u002fb\\u003e %{customdata[2]}\\u003cbr\\u003e\\u003cbr\\u003e%{customdata[1]}\\u003cbr\\u003e\\u003cbr\\u003eX: %{x:.3f}\\u003cbr\\u003eY: %{y:.3f}\\u003cbr\\u003eZ: %{z:.3f}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"marker\":{\"color\":\"#AB63FA\",\"line\":{\"color\":\"DarkSlateGrey\",\"width\":0.5},\"opacity\":0.9,\"size\":7},\"mode\":\"markers\",\"name\":\"preposición\",\"x\":{\"dtype\":\"f4\",\"bdata\":\"dgbdQK4n9EAHx\\u002flAK5ruQBCU9kB7aehAlvfjQN8Q+kA9Af1AlEz1QL+L7EDxX\\u002fRA\"},\"y\":{\"dtype\":\"f4\",\"bdata\":\"oCc0QR\\u002f1KEFIPyxBhXUtQQrKMkFfPCpBR5cxQb+UJkEjfy5BpLUoQZIXQEEjpjFB\"},\"z\":{\"dtype\":\"f4\",\"bdata\":\"rdc+QDSn6T+czsI\\u002f\\u002fbzWP1PnhEAI3YtAGdwVQJzX+j\\u002fgGOw\\u002flj6+P5XJe0DOk9I\\u002f\"},\"type\":\"scatter3d\",\"textfont\":{\"size\":9},\"textposition\":\"top center\"},{\"customdata\":[[\"cuales\",\"\\u003cb\\u003eGénero:\\u003c\\u002fb\\u003e masculino\\u003cbr\\u003e\\u003cb\\u003eNúmero:\\u003c\\u002fb\\u003e plural\\u003cbr\\u003e\\u003cb\\u003eTipo Espec.:\\u003c\\u002fb\\u003e Palabra\\u003cbr\\u003e\\u003cb\\u003ePersona:\\u003c\\u002fb\\u003e tercera\\u003cbr\\u003e\\u003cb\\u003eCaso:\\u003c\\u002fb\\u003e nominativo\\u003cbr\\u003e\\u003cb\\u003eTonicidad:\\u003c\\u002fb\\u003e átono\\u003cbr\\u003e\\u003cb\\u003eReferente:\\u003c\\u002fb\\u003e puertos de entrada\",18]],\"hovertemplate\":\"\\u003cb\\u003e\\u003cu\\u003e%{customdata[0]}\\u003c\\u002fu\\u003e\\u003c\\u002fb\\u003e\\u003cbr\\u003e\\u003cb\\u003eCategoría:\\u003c\\u002fb\\u003e pronombre | \\u003cb\\u003eÍndice:\\u003c\\u002fb\\u003e %{customdata[2]}\\u003cbr\\u003e\\u003cbr\\u003e%{customdata[1]}\\u003cbr\\u003e\\u003cbr\\u003eX: %{x:.3f}\\u003cbr\\u003eY: %{y:.3f}\\u003cbr\\u003eZ: %{z:.3f}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"marker\":{\"color\":\"#FFA15A\",\"line\":{\"color\":\"DarkSlateGrey\",\"width\":0.5},\"opacity\":0.9,\"size\":7},\"mode\":\"markers\",\"name\":\"pronombre\",\"x\":{\"dtype\":\"f4\",\"bdata\":\"k0zJQA==\"},\"y\":{\"dtype\":\"f4\",\"bdata\":\"cnI6QQ==\"},\"z\":{\"dtype\":\"f4\",\"bdata\":\"DEBsQA==\"},\"type\":\"scatter3d\",\"textfont\":{\"size\":9},\"textposition\":\"top center\"},{\"customdata\":[[\"configuración\",\"\\u003cb\\u003eLema:\\u003c\\u002fb\\u003e configuración\\u003cbr\\u003e\\u003cb\\u003eGénero:\\u003c\\u002fb\\u003e femenino\\u003cbr\\u003e\\u003cb\\u003eNúmero:\\u003c\\u002fb\\u003e singular\\u003cbr\\u003e\\u003cb\\u003eTipo Espec.:\\u003c\\u002fb\\u003e Palabra\\u003cbr\\u003e\\u003cb\\u003eDiminutivo:\\u003c\\u002fb\\u003e configuracioncilla\\u003cbr\\u003e\\u003cb\\u003eAumentativo:\\u003c\\u002fb\\u003e configuracazón\\u003cbr\\u003e\\u003cb\\u003eDef. Context.:\\u003c\\u002fb\\u003e Ajustes o parámetros de un dispositivo.\\u003cbr\\u003e\\u003cb\\u003eDef. Gral.:\\u003c\\u002fb\\u003e Acción y efecto de configurar.\",3],[\"dispositivo\",\"\\u003cb\\u003eLema:\\u003c\\u002fb\\u003e dispositivo\\u003cbr\\u003e\\u003cb\\u003eGénero:\\u003c\\u002fb\\u003e masculino\\u003cbr\\u003e\\u003cb\\u003eNúmero:\\u003c\\u002fb\\u003e singular\\u003cbr\\u003e\\u003cb\\u003eTipo Espec.:\\u003c\\u002fb\\u003e Palabra\\u003cbr\\u003e\\u003cb\\u003eDiminutivo:\\u003c\\u002fb\\u003e dispositivito\\u003cbr\\u003e\\u003cb\\u003eAumentativo:\\u003c\\u002fb\\u003e dispositivote\\u003cbr\\u003e\\u003cb\\u003eDef. Context.:\\u003c\\u002fb\\u003e Aparato electrónico.\\u003cbr\\u003e\\u003cb\\u003eDef. Gral.:\\u003c\\u002fb\\u003e Aparato o instrumento.\",6],[\"puertos\",\"\\u003cb\\u003eLema:\\u003c\\u002fb\\u003e puerto\\u003cbr\\u003e\\u003cb\\u003eGénero:\\u003c\\u002fb\\u003e masculino\\u003cbr\\u003e\\u003cb\\u003eNúmero:\\u003c\\u002fb\\u003e plural\\u003cbr\\u003e\\u003cb\\u003eTipo Espec.:\\u003c\\u002fb\\u003e Palabra\\u003cbr\\u003e\\u003cb\\u003eDiminutivo:\\u003c\\u002fb\\u003e puertocito\\u003cbr\\u003e\\u003cb\\u003eAumentativo:\\u003c\\u002fb\\u003e portazo\\u003cbr\\u003e\\u003cb\\u003eDef. Context.:\\u003c\\u002fb\\u003e Conectores físicos de un dispositivo.\\u003cbr\\u003e\\u003cb\\u003eDef. Gral.:\\u003c\\u002fb\\u003e Lugar donde se puede entrar o salir.\",13],[\"entrada\",\"\\u003cb\\u003eLema:\\u003c\\u002fb\\u003e entrada\\u003cbr\\u003e\\u003cb\\u003eGénero:\\u003c\\u002fb\\u003e femenino\\u003cbr\\u003e\\u003cb\\u003eNúmero:\\u003c\\u002fb\\u003e singular\\u003cbr\\u003e\\u003cb\\u003eTipo Espec.:\\u003c\\u002fb\\u003e Palabra\\u003cbr\\u003e\\u003cb\\u003eDiminutivo:\\u003c\\u002fb\\u003e entradita\\u003cbr\\u003e\\u003cb\\u003eAumentativo:\\u003c\\u002fb\\u003e entradera\\u003cbr\\u003e\\u003cb\\u003eDef. Context.:\\u003c\\u002fb\\u003e Punto de acceso para señales o datos.\\u003cbr\\u003e\\u003cb\\u003eDef. Gral.:\\u003c\\u002fb\\u003e Acción y efecto de entrar.\",15],[\"parte\",\"\\u003cb\\u003eLema:\\u003c\\u002fb\\u003e parte\\u003cbr\\u003e\\u003cb\\u003eGénero:\\u003c\\u002fb\\u003e femenino\\u003cbr\\u003e\\u003cb\\u003eNúmero:\\u003c\\u002fb\\u003e singular\\u003cbr\\u003e\\u003cb\\u003eTipo Espec.:\\u003c\\u002fb\\u003e Palabra\\u003cbr\\u003e\\u003cb\\u003eDiminutivo:\\u003c\\u002fb\\u003e partita\\u003cbr\\u003e\\u003cb\\u003eAumentativo:\\u003c\\u002fb\\u003e partazo\\u003cbr\\u003e\\u003cb\\u003eDef. Context.:\\u003c\\u002fb\\u003e Sección o zona de un objeto.\\u003cbr\\u003e\\u003cb\\u003eDef. Gral.:\\u003c\\u002fb\\u003e Porción o fragmento de algo.\",23],[\"modelo\",\"\\u003cb\\u003eLema:\\u003c\\u002fb\\u003e modelo\\u003cbr\\u003e\\u003cb\\u003eGénero:\\u003c\\u002fb\\u003e masculino\\u003cbr\\u003e\\u003cb\\u003eNúmero:\\u003c\\u002fb\\u003e singular\\u003cbr\\u003e\\u003cb\\u003eTipo Espec.:\\u003c\\u002fb\\u003e Palabra\\u003cbr\\u003e\\u003cb\\u003eDiminutivo:\\u003c\\u002fb\\u003e modelito\\u003cbr\\u003e\\u003cb\\u003eAumentativo:\\u003c\\u002fb\\u003e modelón\\u003cbr\\u003e\\u003cb\\u003eDef. Context.:\\u003c\\u002fb\\u003e Versión específica de un dispositivo.\\u003cbr\\u003e\\u003cb\\u003eDef. Gral.:\\u003c\\u002fb\\u003e Patrón o ejemplo a seguir.\",27],[\"conectores\",\"\\u003cb\\u003eLema:\\u003c\\u002fb\\u003e conector\\u003cbr\\u003e\\u003cb\\u003eGénero:\\u003c\\u002fb\\u003e masculino\\u003cbr\\u003e\\u003cb\\u003eNúmero:\\u003c\\u002fb\\u003e plural\\u003cbr\\u003e\\u003cb\\u003eTipo Espec.:\\u003c\\u002fb\\u003e Palabra\\u003cbr\\u003e\\u003cb\\u003eDiminutivo:\\u003c\\u002fb\\u003e conectitos\\u003cbr\\u003e\\u003cb\\u003eAumentativo:\\u003c\\u002fb\\u003e conectazos\\u003cbr\\u003e\\u003cb\\u003eDef. Context.:\\u003c\\u002fb\\u003e Elementos que permiten la conexión física.\\u003cbr\\u003e\\u003cb\\u003eDef. Gral.:\\u003c\\u002fb\\u003e Elemento que une o conecta.\",35],[\"cable\",\"\\u003cb\\u003eLema:\\u003c\\u002fb\\u003e cable\\u003cbr\\u003e\\u003cb\\u003eGénero:\\u003c\\u002fb\\u003e masculino\\u003cbr\\u003e\\u003cb\\u003eNúmero:\\u003c\\u002fb\\u003e singular\\u003cbr\\u003e\\u003cb\\u003eTipo Espec.:\\u003c\\u002fb\\u003e Palabra\\u003cbr\\u003e\\u003cb\\u003eDiminutivo:\\u003c\\u002fb\\u003e cablecito\\u003cbr\\u003e\\u003cb\\u003eAumentativo:\\u003c\\u002fb\\u003e cablete\\u003cbr\\u003e\\u003cb\\u003eDef. Context.:\\u003c\\u002fb\\u003e Conductor eléctrico para transmisión de datos.\\u003cbr\\u003e\\u003cb\\u003eDef. Gral.:\\u003c\\u002fb\\u003e Hilo o cuerda metálica.\",37],[\"HDMI\",\"\\u003cb\\u003eLema:\\u003c\\u002fb\\u003e HDMI\\u003cbr\\u003e\\u003cb\\u003eGénero:\\u003c\\u002fb\\u003e masculino\\u003cbr\\u003e\\u003cb\\u003eNúmero:\\u003c\\u002fb\\u003e singular\\u003cbr\\u003e\\u003cb\\u003eTipo Espec.:\\u003c\\u002fb\\u003e Palabra\\u003cbr\\u003e\\u003cb\\u003eDef. Context.:\\u003c\\u002fb\\u003e Interfaz multimedia de alta definición.\",38],[\"fallos\",\"\\u003cb\\u003eLema:\\u003c\\u002fb\\u003e fallo\\u003cbr\\u003e\\u003cb\\u003eGénero:\\u003c\\u002fb\\u003e masculino\\u003cbr\\u003e\\u003cb\\u003eNúmero:\\u003c\\u002fb\\u003e plural\\u003cbr\\u003e\\u003cb\\u003eTipo Espec.:\\u003c\\u002fb\\u003e Palabra\\u003cbr\\u003e\\u003cb\\u003eDiminutivo:\\u003c\\u002fb\\u003e fallitos\\u003cbr\\u003e\\u003cb\\u003eAumentativo:\\u003c\\u002fb\\u003e fallazos\\u003cbr\\u003e\\u003cb\\u003eDef. Context.:\\u003c\\u002fb\\u003e Errores o problemas en la transmisión.\\u003cbr\\u003e\\u003cb\\u003eDef. Gral.:\\u003c\\u002fb\\u003e Defecto o error.\",43],[\"transmisión\",\"\\u003cb\\u003eLema:\\u003c\\u002fb\\u003e transmisión\\u003cbr\\u003e\\u003cb\\u003eGénero:\\u003c\\u002fb\\u003e femenino\\u003cbr\\u003e\\u003cb\\u003eNúmero:\\u003c\\u002fb\\u003e singular\\u003cbr\\u003e\\u003cb\\u003eTipo Espec.:\\u003c\\u002fb\\u003e Palabra\\u003cbr\\u003e\\u003cb\\u003eDiminutivo:\\u003c\\u002fb\\u003e transmisióncilla\\u003cbr\\u003e\\u003cb\\u003eAumentativo:\\u003c\\u002fb\\u003e transmisiónazo\\u003cbr\\u003e\\u003cb\\u003eDef. Context.:\\u003c\\u002fb\\u003e Envío de datos a través de un medio.\\u003cbr\\u003e\\u003cb\\u003eDef. Gral.:\\u003c\\u002fb\\u003e Acción y efecto de transmitir.\",45],[\"datos\",\"\\u003cb\\u003eLema:\\u003c\\u002fb\\u003e dato\\u003cbr\\u003e\\u003cb\\u003eGénero:\\u003c\\u002fb\\u003e masculino\\u003cbr\\u003e\\u003cb\\u003eNúmero:\\u003c\\u002fb\\u003e plural\\u003cbr\\u003e\\u003cb\\u003eTipo Espec.:\\u003c\\u002fb\\u003e Palabra\\u003cbr\\u003e\\u003cb\\u003eDiminutivo:\\u003c\\u002fb\\u003e datitos\\u003cbr\\u003e\\u003cb\\u003eAumentativo:\\u003c\\u002fb\\u003e datazos\\u003cbr\\u003e\\u003cb\\u003eDef. Context.:\\u003c\\u002fb\\u003e Información digital.\\u003cbr\\u003e\\u003cb\\u003eDef. Gral.:\\u003c\\u002fb\\u003e Información o noticia.\",47],[\"proceso\",\"\\u003cb\\u003eLema:\\u003c\\u002fb\\u003e proceso\\u003cbr\\u003e\\u003cb\\u003eGénero:\\u003c\\u002fb\\u003e masculino\\u003cbr\\u003e\\u003cb\\u003eNúmero:\\u003c\\u002fb\\u003e singular\\u003cbr\\u003e\\u003cb\\u003eTipo Espec.:\\u003c\\u002fb\\u003e Palabra\\u003cbr\\u003e\\u003cb\\u003eDiminutivo:\\u003c\\u002fb\\u003e procesito\\u003cbr\\u003e\\u003cb\\u003eAumentativo:\\u003c\\u002fb\\u003e procesote\\u003cbr\\u003e\\u003cb\\u003eDef. Context.:\\u003c\\u002fb\\u003e Secuencia de acciones para lograr algo.\\u003cbr\\u003e\\u003cb\\u003eDef. Gral.:\\u003c\\u002fb\\u003e Serie de acciones o fenómenos relacionados.\",50],[\"sincronización\",\"\\u003cb\\u003eLema:\\u003c\\u002fb\\u003e sincronización\\u003cbr\\u003e\\u003cb\\u003eGénero:\\u003c\\u002fb\\u003e femenino\\u003cbr\\u003e\\u003cb\\u003eNúmero:\\u003c\\u002fb\\u003e singular\\u003cbr\\u003e\\u003cb\\u003eTipo Espec.:\\u003c\\u002fb\\u003e Palabra\\u003cbr\\u003e\\u003cb\\u003eDiminutivo:\\u003c\\u002fb\\u003e sincronizaciócilla\\u003cbr\\u003e\\u003cb\\u003eAumentativo:\\u003c\\u002fb\\u003e sincronizaciónazo\\u003cbr\\u003e\\u003cb\\u003eDef. Context.:\\u003c\\u002fb\\u003e Coordinación temporal de dispositivos.\\u003cbr\\u003e\\u003cb\\u003eDef. Gral.:\\u003c\\u002fb\\u003e Acción y efecto de sincronizar.\",52]],\"hovertemplate\":\"\\u003cb\\u003e\\u003cu\\u003e%{customdata[0]}\\u003c\\u002fu\\u003e\\u003c\\u002fb\\u003e\\u003cbr\\u003e\\u003cb\\u003eCategoría:\\u003c\\u002fb\\u003e sustantivo | \\u003cb\\u003eÍndice:\\u003c\\u002fb\\u003e %{customdata[2]}\\u003cbr\\u003e\\u003cbr\\u003e%{customdata[1]}\\u003cbr\\u003e\\u003cbr\\u003eX: %{x:.3f}\\u003cbr\\u003eY: %{y:.3f}\\u003cbr\\u003eZ: %{z:.3f}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"marker\":{\"color\":\"#19D3F3\",\"line\":{\"color\":\"DarkSlateGrey\",\"width\":0.5},\"opacity\":0.9,\"size\":7},\"mode\":\"markers\",\"name\":\"sustantivo\",\"x\":{\"dtype\":\"f4\",\"bdata\":\"xqbPQHhp2kAaXrxA0un0QIBI4UBndNNAKz3eQHFpzUBYJ85AIuCfQF7V0UATn6dAEufMQMjlxEA=\"},\"y\":{\"dtype\":\"f4\",\"bdata\":\"jbJMQcR6UEHgsEJBVTo7QaSfN0HlXE1ByKBHQUkRMEG4izVBprVJQZ3gUkG\\u002fNUdBFYNQQWaiT0E=\"},\"z\":{\"dtype\":\"f4\",\"bdata\":\"TXGpQCzBn0AvpWpAaaOHQKB4bEB8xYxAdmqEQBArtUCfZrpASdhPQD7PrkDNglhACDWJQEq2skA=\"},\"type\":\"scatter3d\",\"textfont\":{\"size\":9},\"textposition\":\"top center\"},{\"customdata\":[[\"realizar\",\"\\u003cb\\u003eTipo Espec.:\\u003c\\u002fb\\u003e Palabra\\u003cbr\\u003e\\u003cb\\u003eInfinitivo:\\u003c\\u002fb\\u003e realizar\\u003cbr\\u003e\\u003cb\\u003eModo:\\u003c\\u002fb\\u003e infinitivo\\u003cbr\\u003e\\u003cb\\u003eParticipio:\\u003c\\u002fb\\u003e realizado\\u003cbr\\u003e\\u003cb\\u003eGerundio:\\u003c\\u002fb\\u003e realizando\\u003cbr\\u003e\\u003cb\\u003eTransitiv.:\\u003c\\u002fb\\u003e transitivo\\u003cbr\\u003e\\u003cb\\u003eDef. Gral.:\\u003c\\u002fb\\u003e Llevar a cabo, ejecutar, hacer algo.\",1],[\"asegúrese\",\"\\u003cb\\u003eNúmero:\\u003c\\u002fb\\u003e singular\\u003cbr\\u003e\\u003cb\\u003eTipo Espec.:\\u003c\\u002fb\\u003e Palabra\\u003cbr\\u003e\\u003cb\\u003eInfinitivo:\\u003c\\u002fb\\u003e asegurar\\u003cbr\\u003e\\u003cb\\u003eModo:\\u003c\\u002fb\\u003e imperativo\\u003cbr\\u003e\\u003cb\\u003ePersona:\\u003c\\u002fb\\u003e usted\\u003cbr\\u003e\\u003cb\\u003eParticipio:\\u003c\\u002fb\\u003e asegurado\\u003cbr\\u003e\\u003cb\\u003eGerundio:\\u003c\\u002fb\\u003e asegurando\\u003cbr\\u003e\\u003cb\\u003eTransitiv.:\\u003c\\u002fb\\u003e transitivo\\u003cbr\\u003e\\u003cb\\u003eDef. Gral.:\\u003c\\u002fb\\u003e Tener la certeza de algo.\",8],[\"verificar\",\"\\u003cb\\u003eTipo Espec.:\\u003c\\u002fb\\u003e Palabra\\u003cbr\\u003e\\u003cb\\u003eInfinitivo:\\u003c\\u002fb\\u003e verificar\\u003cbr\\u003e\\u003cb\\u003eModo:\\u003c\\u002fb\\u003e infinitivo\\u003cbr\\u003e\\u003cb\\u003eParticipio:\\u003c\\u002fb\\u003e verificado\\u003cbr\\u003e\\u003cb\\u003eGerundio:\\u003c\\u002fb\\u003e verificando\\u003cbr\\u003e\\u003cb\\u003eTransitiv.:\\u003c\\u002fb\\u003e transitivo\\u003cbr\\u003e\\u003cb\\u003eDef. Gral.:\\u003c\\u002fb\\u003e Comprobar la exactitud o veracidad de algo.\",10],[\"suelen\",\"\\u003cb\\u003eNúmero:\\u003c\\u002fb\\u003e plural\\u003cbr\\u003e\\u003cb\\u003eTipo Espec.:\\u003c\\u002fb\\u003e Palabra\\u003cbr\\u003e\\u003cb\\u003eInfinitivo:\\u003c\\u002fb\\u003e soler\\u003cbr\\u003e\\u003cb\\u003eModo:\\u003c\\u002fb\\u003e indicativo\\u003cbr\\u003e\\u003cb\\u003eTiempo:\\u003c\\u002fb\\u003e presente\\u003cbr\\u003e\\u003cb\\u003ePersona:\\u003c\\u002fb\\u003e tercera\\u003cbr\\u003e\\u003cb\\u003eParticipio:\\u003c\\u002fb\\u003e solído\\u003cbr\\u003e\\u003cb\\u003eGerundio:\\u003c\\u002fb\\u003e soliendo\\u003cbr\\u003e\\u003cb\\u003eTransitiv.:\\u003c\\u002fb\\u003e intransitivo\\u003cbr\\u003e\\u003cb\\u003eDef. Gral.:\\u003c\\u002fb\\u003e Acostumbrar, ser habitual.\",19],[\"ubicarse\",\"\\u003cb\\u003eTipo Espec.:\\u003c\\u002fb\\u003e Palabra\\u003cbr\\u003e\\u003cb\\u003eInfinitivo:\\u003c\\u002fb\\u003e ubicarse\\u003cbr\\u003e\\u003cb\\u003eModo:\\u003c\\u002fb\\u003e infinitivo\\u003cbr\\u003e\\u003cb\\u003eParticipio:\\u003c\\u002fb\\u003e ubicado\\u003cbr\\u003e\\u003cb\\u003eGerundio:\\u003c\\u002fb\\u003e ubicándose\\u003cbr\\u003e\\u003cb\\u003eTransitiv.:\\u003c\\u002fb\\u003e intransitivo\\u003cbr\\u003e\\u003cb\\u003eDef. Gral.:\\u003c\\u002fb\\u003e Situarse, estar en un lugar.\",20],[\"estén\",\"\\u003cb\\u003eNúmero:\\u003c\\u002fb\\u003e plural\\u003cbr\\u003e\\u003cb\\u003eTipo Espec.:\\u003c\\u002fb\\u003e Palabra\\u003cbr\\u003e\\u003cb\\u003eInfinitivo:\\u003c\\u002fb\\u003e estar\\u003cbr\\u003e\\u003cb\\u003eModo:\\u003c\\u002fb\\u003e subjuntivo\\u003cbr\\u003e\\u003cb\\u003eTiempo:\\u003c\\u002fb\\u003e presente\\u003cbr\\u003e\\u003cb\\u003ePersona:\\u003c\\u002fb\\u003e tercera\\u003cbr\\u003e\\u003cb\\u003eParticipio:\\u003c\\u002fb\\u003e estado\\u003cbr\\u003e\\u003cb\\u003eGerundio:\\u003c\\u002fb\\u003e estando\\u003cbr\\u003e\\u003cb\\u003eTransitiv.:\\u003c\\u002fb\\u003e intransitivo\\u003cbr\\u003e\\u003cb\\u003eDef. Gral.:\\u003c\\u002fb\\u003e Encontrarse en un lugar o situación.\",30],[\"evitando\",\"\\u003cb\\u003eTipo Espec.:\\u003c\\u002fb\\u003e Palabra\\u003cbr\\u003e\\u003cb\\u003eInfinitivo:\\u003c\\u002fb\\u003e evitar\\u003cbr\\u003e\\u003cb\\u003eModo:\\u003c\\u002fb\\u003e gerundio\\u003cbr\\u003e\\u003cb\\u003eTiempo:\\u003c\\u002fb\\u003e presente\\u003cbr\\u003e\\u003cb\\u003eParticipio:\\u003c\\u002fb\\u003e evitado\\u003cbr\\u003e\\u003cb\\u003eGerundio:\\u003c\\u002fb\\u003e evitando\\u003cbr\\u003e\\u003cb\\u003eTransitiv.:\\u003c\\u002fb\\u003e transitivo\\u003cbr\\u003e\\u003cb\\u003eDef. Gral.:\\u003c\\u002fb\\u003e Prevenir o impedir que algo ocurra.\",40]],\"hovertemplate\":\"\\u003cb\\u003e\\u003cu\\u003e%{customdata[0]}\\u003c\\u002fu\\u003e\\u003c\\u002fb\\u003e\\u003cbr\\u003e\\u003cb\\u003eCategoría:\\u003c\\u002fb\\u003e verbo | \\u003cb\\u003eÍndice:\\u003c\\u002fb\\u003e %{customdata[2]}\\u003cbr\\u003e\\u003cbr\\u003e%{customdata[1]}\\u003cbr\\u003e\\u003cbr\\u003eX: %{x:.3f}\\u003cbr\\u003eY: %{y:.3f}\\u003cbr\\u003eZ: %{z:.3f}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"marker\":{\"color\":\"#FF6692\",\"line\":{\"color\":\"DarkSlateGrey\",\"width\":0.5},\"opacity\":0.9,\"size\":7},\"mode\":\"markers\",\"name\":\"verbo\",\"x\":{\"dtype\":\"f4\",\"bdata\":\"GunCQCuW3UBjm8xAhubvQD0j20Az2fRAIoXjQA==\"},\"y\":{\"dtype\":\"f4\",\"bdata\":\"Da4\\u002fQcAtLUEH9EFBAEcsQRydN0FUEC5BvoVBQQ==\"},\"z\":{\"dtype\":\"f4\",\"bdata\":\"vPykQDNol0DCCKpA9xZ4QK6XmUANmYRABlmfQA==\"},\"type\":\"scatter3d\",\"textfont\":{\"size\":9},\"textposition\":\"top center\"},{\"customdata\":[[\"\\u003cb\\u003eTipo:\\u003c\\u002fb\\u003e TextoCompleto\\u003cbr\\u003e\\u003cb\\u003eTexto:\\u003c\\u002fb\\u003e Para realizar la configuración óptima del dispositivo,...\"]],\"hovertemplate\":\"%{customdata[0]}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"marker\":{\"color\":\"green\",\"line\":{\"color\":\"DarkSlateGrey\",\"width\":1},\"size\":10,\"symbol\":\"diamond\"},\"mode\":\"markers\",\"name\":\"Texto Completo\",\"x\":[6.645977020263672],\"y\":[12.551560401916504],\"z\":[5.978421688079834],\"type\":\"scatter3d\",\"textfont\":{\"size\":9},\"textposition\":\"top center\"},{\"hoverinfo\":\"none\",\"line\":{\"color\":\"rgba(0,128,0,0.5)\",\"dash\":\"dot\",\"width\":1.5},\"mode\":\"lines\",\"showlegend\":false,\"x\":[6.645977020263672,6.907038688659668],\"y\":[12.551560401916504,11.259674072265625],\"z\":[5.978421688079834,2.9819138050079346],\"type\":\"scatter3d\"},{\"customdata\":[[\"\\u003cb\\u003eTipo:\\u003c\\u002fb\\u003e Unidad\\u003cbr\\u003e\\u003cb\\u003eTexto:\\u003c\\u002fb\\u003e Para realizar la configuración óptima del dispositivo,...\",1],[\"\\u003cb\\u003eTipo:\\u003c\\u002fb\\u003e Unidad\\u003cbr\\u003e\\u003cb\\u003eTexto:\\u003c\\u002fb\\u003e los cuales suelen ubicarse en la parte posterior según el...\",2]],\"hovertemplate\":\"\\u003cb\\u003eUnidad Detectada #%{customdata[1]}\\u003c\\u002fb\\u003e\\u003cbr\\u003e\\u003cbr\\u003e%{customdata[0]}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"marker\":{\"color\":\"orange\",\"line\":{\"width\":1},\"size\":10,\"symbol\":\"cross\"},\"mode\":\"markers\",\"name\":\"Unidad Detectada\",\"x\":{\"dtype\":\"f4\",\"bdata\":\"QHnLQFSDy0A=\"},\"y\":{\"dtype\":\"f4\",\"bdata\":\"AeJIQY5lT0E=\"},\"z\":{\"dtype\":\"f4\",\"bdata\":\"ulnCQF06vEA=\"},\"type\":\"scatter3d\",\"textfont\":{\"size\":9},\"textposition\":\"top center\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scattermap\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermap\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"#C8D4E3\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2}}},\"margin\":{\"l\":10,\"r\":10,\"t\":90,\"b\":10},\"scene\":{\"xaxis\":{\"title\":{\"text\":\"UMAP X\"},\"showticklabels\":false,\"backgroundcolor\":\"rgba(0,0,0,0)\",\"gridcolor\":\"lightgrey\"},\"yaxis\":{\"title\":{\"text\":\"UMAP Y\"},\"showticklabels\":false,\"backgroundcolor\":\"rgba(0,0,0,0)\",\"gridcolor\":\"lightgrey\"},\"zaxis\":{\"title\":{\"text\":\"UMAP Z\"},\"showticklabels\":false,\"backgroundcolor\":\"rgba(0,0,0,0)\",\"gridcolor\":\"lightgrey\"},\"aspectratio\":{\"x\":1,\"y\":1,\"z\":0.7}},\"legend\":{\"title\":{\"text\":\"Tipo \\u002f Categoría\"}},\"title\":{\"text\":\"Mapa Semántico 3D (UMAP)\\u003cbr\\u003eTexto: \\u003ci\\u003ePara realizar la configuración óptima del dispositivo, asegúrese de verificar que los puertos de entrada, los [...]\\u003c\\u002fi\\u003e\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('79a00500-9ba6-4579-a119-51b3da4d4712');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Fin del Proceso del Chunk 10 (v4 - Tooltips Dinámicos) ---\n"
          ]
        }
      ]
    }
  ]
}